{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Of Scope and Symbol Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All modern high-level programming languages have some notion of [scope](https://en.wikipedia.org/wiki/Scope_(computer_science)) applied to symbols that can appear in a program.  The scope of a program symbol defines the lifetime or visibility of that symbol. Program symbols that are subject to scoping rules include variable as well as function names and in object oriented languages it also includes type/class symbols among many other kind of symbols that can appear in a programming language.  Scoping of program symbols evolved in programming languages as programs became more complex and limiting the visibility of program symbols was necessary in order to avoid name clashes sources of bugs.  \n",
    "\n",
    "Early dialects of Fortran and Basic only had global scope in that all program symbols where visible everywhere in a program.  Nowadays, almost all programming language implement static or lexical scoping where the scope of a program symbol can be determined by just looking at the program text.  This is in contrast with dynamic scoping where the scope of a program symbol is determined at runtime.  Here we only look at lexical scoping.\n",
    "\n",
    "If a symbol is no longer available or accessible then we say that it is *out of scope*.\n",
    "Consider function local symbols such as parameters variables.  These symbols are only available to the code of the function but are out of scope for all other code.\n",
    "\n",
    "Perhaps the simplest scope is the *block scope* characterized in C-like languages with the open and closed curly braces.  All declarations of program symbols within the curly braces are local to that block scope and become out of scope as soon the execution thread leaves that scope.\n",
    "\n",
    "The languages we have defined so far only have global scope, that is, all symbols, in particular variable names, are visible everywhere. This allowed us to have variables defined by just using them.  Once we introduce scope we need a notion declaration to assert in which scope a symbol is visible.  Here we start with variable declarations and in later chapters we will introduce additional symbols such as function names subject to scoping rules.\n",
    "\n",
    "It is interesting that Python takes a very different approach to scoping by assuming that all variables are function local unless they are declared explicitly as *global* variables.  In our approach we are going to be more traditional and allow the user to specify explicitly in which scope a variable is visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let the notebook access the code folder\n",
    "import sys\n",
    "sys.path.insert(1,\"code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Cuppa2 Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extend our Cuppa1 language with variable declarations of the form,\n",
    "```\n",
    "declare x = 10;\n",
    "```\n",
    "This particular statement declares the variable `x` in the current scope and initializes it to the value 10. If the current scope is the global (outermost) scope then we call `x` a *global* variable otherwise it is considered a *local* variable within some scope.  We call this new language Cuppa2 which is syntactically identical to Cuppa1 with the exception of the `declare` statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the grammar of Cuppa2 which of course is identical to the grammar of Cuppa1 with the exception of the addition of the declaration statement under the non-terminal `stmt`,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "    program : stmt_list\n",
    "\n",
    "    stmt_list : stmt stmt_list\n",
    "              | empty\n",
    "\n",
    "    stmt : DECLARE ID opt_init opt_semi\n",
    "         | ID '=' exp opt_semi\n",
    "         | GET ID opt_semi\n",
    "         | PUT exp opt_semi\n",
    "         | WHILE '(' exp ')' stmt\n",
    "         | IF '(' exp ')' stmt opt_else\n",
    "         | '{' stmt_list '}'\n",
    "\n",
    "    opt_init : '=' exp\n",
    "             | empty\n",
    "             \n",
    "    opt_else : ELSE stmt\n",
    "             | empty\n",
    "             \n",
    "    opt_semi : ';'\n",
    "             | empty\n",
    "\n",
    "    exp : exp PLUS exp\n",
    "        | exp MINUS exp\n",
    "        | exp TIMES exp\n",
    "        | exp DIVIDE exp\n",
    "        | exp EQ exp\n",
    "        | exp LE exp\n",
    "        | INTEGER\n",
    "        | ID\n",
    "        | '(' exp ')'\n",
    "        | MINUS exp %prec UMINUS\n",
    "        | NOT exp\n",
    "\n",
    "    empty :\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parser specification [(`cuppa2_gram.py`)](code/cuppa2_gram.py) and the lexer specification [(`cuppa2_lex.py`)](code/cuppa2_lex.py) for Cuppa2 are available in the [`code`](code) folder.  We can test our parser and lexer code to make sure it works as expected,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating LALR tables\n",
      "WARNING: 1 shift/reduce conflict\n"
     ]
    }
   ],
   "source": [
    "from cuppa2_lex import lexer\n",
    "from cuppa2_gram import parser\n",
    "\n",
    "parser.parse(\"declare x = 1; put x\", lexer=lexer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuppa2 Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Cuppa2 we can now write programs that have scoped variable declarations.  Here is a program that uses simple block scopes to limit the visibility of different declarations of the variable `x`,\n",
    "```C\n",
    "// declare a global instance of x\n",
    "declare x = 1;\n",
    "\n",
    "// create a local block scope\n",
    "{\n",
    "    // declare a local instance of x\n",
    "    declare x = 2;\n",
    "    // print out the value of local instance\n",
    "    put x;\n",
    "}\n",
    "\n",
    "// create another local block scope\n",
    "{\n",
    "    // declare a local instance of x\n",
    "    declare x = 3;\n",
    "    // print out the value of local instance\n",
    "    put x;\n",
    "}\n",
    "\n",
    "// print out the value of the global instance\n",
    "put x;\n",
    "```\n",
    "The expected output of this program is,\n",
    "```\n",
    "2 3 1\n",
    "```\n",
    "What is interesting is that as soon as we introduce scope we can observe the phenomenon of [*variable shadowing*](https://en.wikipedia.org/wiki/Variable_shadowing). As soon as we declare the variable `x` in a local block scope we see that the global instance of `x` is no longer visible to the code in the local scope (look at the output of the corresponding `put` statement) and we say that the global instance of `x` is *shadowed* by the local instance of `x`.\n",
    "\n",
    "Variable shadowing is the source of many subtle bugs in software where global variables often represent global parameters.  If not careful such a global parameter can easily be shadowed by a carelessly introduced local variable making that global parameter inaccessible to the code in that local scope.  Large software organization such as Microsoft have recognized that problem and have introduced coding standards to alleviate this source of bugs.  For example, in Microsoft's [Coding Style Conventions](https://docs.microsoft.com/en-us/windows/win32/stg/coding-style-conventions) all global variables have to start with the prefix `g_` and that prefix is forbidden for local variables therefore making it impossible for a local variable to shadow a global variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing scope also introduces *non-local access* of variables in the sense that scoping forces us to think about reading and modifying the values of variables which are outside of our local scope.  Take a look at the following program which reads and updates the global variable `x` from within a local scope,\n",
    "```C\n",
    "// declare global instance of x\n",
    "declare x = 2;\n",
    "\n",
    "// start a local scope\n",
    "{\n",
    "      declare y = 3;\n",
    "      // read and update non-local x\n",
    "      x = y + x;\n",
    "}\n",
    "\n",
    "// print out the updated value of x\n",
    "put x;\n",
    "```\n",
    "The expected output of this program is,\n",
    "```\n",
    "5\n",
    "```\n",
    "In order to deal with scoped programs like the ones above we need a more sophisticated version of our symbol table which up to this point has only been a global dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Symbol Table for supporting Scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to support scoped programs we need something more sophisticated than the symbol table structure that consists of a single global dictionary we have been using so far.  What is perhaps remarkable is that scopes behave like a stack of symbol declarations.  Consider the following program,\n",
    "```C\n",
    "declare x = 1;\n",
    "\n",
    "{\n",
    "    declare y = 2;\n",
    "    \n",
    "    {\n",
    "        declare z = 3;\n",
    "        put x + y + z;\n",
    "    }\n",
    "}\n",
    "```\n",
    "Here we are dealing with three nested scopes and at each scope level we declare a symbol and initialize it.  At the innermost scope we look up all the symbols declared and initialized so far and print out the sum of their values.  The implicit behavior of this program is that if a declaration for a variable cannot be found in the current scope then we search the outer scopes until we reach the global scope.  Once we reach the global scope and we still  cannot find the symbol declaration then we are faced with an error because this means that the variable was not declared properly.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"600\" height=\"4500\" src=\"figures/chap07/1/figure.jpg\">\n",
    "</p>\n",
    "<!-- ![alt text](figures/chap07/1/figure.jpg) -->\n",
    "<p style=\"text-align: center;\">\n",
    "Fig. 1: Visualizing nested scopes as a stack of scopes.\n",
    "</p>\n",
    "\n",
    "We can visualize the nested scopes as a stack of scopes each holding the appropriate declarations (Figure 1).  Here we modeled the scope stack as a linked list of scope objects. It is now easy to interpret the expression at the innermost scope of our program above: if a variable declaration cannot be found in the scope at the top of the stack we simply walk down the stack until we find the variable declaration in question.  If we reach the bottom of the stack, the global scope, and we still haven't found the desired variable declaration then we are faced with a *variable not declared error*.\n",
    "\n",
    "With this view of nested scopes as a stack of scopes it is also pretty straight forward to visualize updating the values of non-local variables: walk down the stack until you find the variable declaration of the variable you want to update and then update it.  It is an error if you do not find a declaration for the variable you want to update.  Try it with this program,\n",
    "```C\n",
    "declare x = 2;\n",
    "\n",
    "{\n",
    "    declare y = 3;\n",
    "    x = x + y;\n",
    "}\n",
    "put x;\n",
    "```\n",
    "The output of this program is `5`.\n",
    "\n",
    "This gives us the basic outline of our new symbol table design: *a stack of dictionaries*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Watch an animation of a program with scoping.  Again, here the stack of dictionaries is modeled as a linked list.\n",
    "\n",
    "<br>\n",
    "<a href=\"http://www.youtube.com/watch?feature=player_embedded&v=uh9Qm5AeVjs\">\n",
    "<img style='border:1px solid #000000' src=\"movie.jpg\" width=\"120\" height=\"90\" />\n",
    "</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbol Table Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new [symbol table](https://en.wikipedia.org/wiki/Symbol_table) design as a stack of scopes has to support the following functionality,\n",
    "\n",
    "* Push a scope.\n",
    "* Pop a scope.\n",
    "* Declare a variable.\n",
    "* Look up a variable.\n",
    "* Update a variable value.\n",
    "\n",
    "In addition, our symbol table design will need to implement our programming language semantics we have relied upon when we worked through the examples in the previous section,\n",
    "\n",
    "* The `declare` statement inserts a variable declaration into the current scope.\n",
    "* A variable look up returns the value associated with a variable from the current scope or the surrounding scopes.\n",
    "* Every variable needs to be declared before use.\n",
    "* No variable can be declared more than once in the current scope.\n",
    "\n",
    "Here the notion of *current scope* is now easy to understand, it is simply the scope at the top of the scope stack in the symbol table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of our symbol table is an object that holds the scope stack and has an appropriate interface to support the functionality mentioned above,\n",
    "```Python\n",
    "CURR_SCOPE = 0\n",
    "\n",
    "class SymTab:\n",
    "\n",
    "    #-------\n",
    "    def __init__(self):\n",
    "        # global scope dictionary must always be present\n",
    "            self.scoped_symtab = [{}]\n",
    "\n",
    "    #-------\n",
    "    def push_scope(self):\n",
    "        # push a new dictionary onto the stack - stack grows to the left\n",
    "        self.scoped_symtab.insert(CURR_SCOPE,{})\n",
    "\n",
    "    #-------\n",
    "    def pop_scope(self):\n",
    "        # pop the left most dictionary off the stack\n",
    "        if len(self.scoped_symtab) == 1:\n",
    "            raise ValueError(\"cannot pop the global scope\")\n",
    "        else:\n",
    "            self.scoped_symtab.pop(CURR_SCOPE)\n",
    "\n",
    "    #-------\n",
    "    def declare_sym(self, sym, init):\n",
    "        # declare the symbol in the current scope: dict @ position 0\n",
    "                 …\n",
    "\n",
    "    #-------\n",
    "    def lookup_sym(self, sym):\n",
    "        # find the first occurrence of sym in the symtab stack\n",
    "        # and return the associated value\n",
    "                 …\n",
    "\n",
    "    #-------\n",
    "    def update_sym(self, sym, val):\n",
    "        # find the first occurrence of sym in the symtab stack\n",
    "        # and update the associated value\n",
    "                 …\n",
    "```\n",
    "The `...` in the code above means *don't worry about the implementation details right now*. We see that the constructor inserts a member `scoped_symtab` into objects of class `SymTab` and initializes it as a list with a single empty dictionary in it.  This is the dictionary for the global scope.  This dictionary has to always be present and it is an error to try to pop this global dictionary off the stack. Next we have the interface that allows us to manipulate the scope stack.  The function `push_scope` inserts a new dictionary on top of the stack.  In this case the top of the stack is at the list position 0.  We do that so that the top of the stack is always reachable by simply looking at the list position 0.   The constant `CURR_SCOPE` refers to that position in the list.  Next we have the function `pop_scope` that removes the dictionary on the top of the stack.  Following the functions that manipulate the scope in the symbol table we have the interface functions that manipulate the symbols within the symbol table.  Let's look at those more carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have the `declare_sym` function,\n",
    "```Python\n",
    "def declare_sym(self, sym, init):\n",
    "    # declare the symbol in the current scope: dict @ position 0\n",
    "        \n",
    "    # first we need to check whether the symbol was already declared\n",
    "    # at this scope\n",
    "    if sym in self.scoped_symtab[CURR_SCOPE]:\n",
    "        raise ValueError(\"symbol {} already declared\".format(sym))\n",
    "        \n",
    "    # enter the symbol in the current scope\n",
    "    scope_dict = self.scoped_symtab[CURR_SCOPE]\n",
    "    scope_dict[sym] = init\n",
    "```\n",
    "This function inserts a symbol together with its value in the current scope.  But before it does so it checks whether the symbol already exists in the current scope.  It it does then it throws an exception according to our rule that *symbols can only be declared once in the current scope*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have the `lookup_sym` function,\n",
    "```Python\n",
    "def lookup_sym(self, sym):\n",
    "    # find the first occurrence of sym in the symtab stack\n",
    "    # and return the associated value\n",
    "\n",
    "    n_scopes = len(self.scoped_symtab)\n",
    "\n",
    "    for scope in range(n_scopes):\n",
    "        if sym in self.scoped_symtab[scope]:\n",
    "            val = self.scoped_symtab[scope].get(sym)\n",
    "            return val\n",
    "\n",
    "    # not found\n",
    "    raise ValueError(\"{} was not declared\".format(sym))\n",
    "```\n",
    "This function finds a symbol declaration in our stack of scopes.  Notice that the function iterates through the stack of scopes starting with the current scope (at position 0 in `scoped_symtab`) all the way to the global scope (the last dictionary in the `scoped_symtab` list).  If it finds a symbol declaration in one of the dictionaries it will break out of the loop and return its associated value.  If the function iterates through the whole stack without finding a declaration of the symbol it drops through the loop and throws an exception indicating that the symbol was not declared enforcing our rule that *variables need to be declared before use*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last function in the `SymTab` interface is the `update_sym` function,\n",
    "```Python\n",
    "def update_sym(self, sym, val):\n",
    "    # find the first occurrence of sym in the symtab stack\n",
    "    # and update the associated value\n",
    "\n",
    "    n_scopes = len(self.scoped_symtab)\n",
    "\n",
    "    for scope in range(n_scopes):\n",
    "        if sym in self.scoped_symtab[scope]:\n",
    "            scope_dict = self.scoped_symtab[scope]\n",
    "            scope_dict[sym] = val\n",
    "            return\n",
    "\n",
    "    # not found\n",
    "    raise ValueError(\"{} was not declared\".format(sym))\n",
    "```\n",
    "The idea here is that we need to find the declaration of a variable closest to our current scope (including the current scope) and update its associated value.  Notice that the code is very similar to the `lookup_sym` function in that it iterates over the stack of scope dictionaries until it finds a declaration of the variable symbol.  As soon as it finds the variable declaration it will update the associated dictionary with the new value and break out of the loop and return.  If it cannot find a declaration record for the variable then it will drop through the loop and throw an exception enforcing the rule that *variables need to be declared before they are used*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source code for the Cuppa2 symbol tables can be found in file [`cuppa2_symtab.py`](code/cuppa2_symtab.py) in the [`code`](code) folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Cuppa2 Interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new symbol table in place we are ready to construct an interpreter for Cuppa2.  It turns out that we can reuse most of the code from our Cuppa1 interpreter with the exception that we have to add new code for the `declare` statement and we have to adjust the code for the block and assignment statements amongst a few other to deal with the new scoped symbol table.  As usual the [Cuppa2 front end](code/cuppa2_frontend_gram.py) generates an AST which our `walk` function will then interpret.  One thing to mention about the front end is that we no longer just put symbols into the symbol as we parse them.  We have to delay that until later when we know more about the scope in which  various variables can appear in.  The AST for Cuppa2 includes one additional type of node compared to the Cuppa1 AST: the `declare` node type.  Other than that the AST for Cuppa1 and Cuppa2 are identical.  The lexer for Cuppa2 is unchanged from the lexer discussed for Cuppa1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our front end by processing a simple program that declares a variable and then prints out its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuppa2_lex import lexer\n",
    "from cuppa2_frontend import parser\n",
    "from cuppa2_state import state\n",
    "from grammar_stuff import dump_AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(seq \n",
      "  |(declare x \n",
      "  |  |(integer 1)) \n",
      "  |(seq \n",
      "  |  |(put \n",
      "  |  |  |(id x)) \n",
      "  |  |(nil)))\n"
     ]
    }
   ],
   "source": [
    "parser.parse(\"declare x = 1; put x\", lexer=lexer)\n",
    "dump_AST(state.AST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to the interpretation tree walker we see that the additional node type in the Cuppa2 AST is reflected in the [interpretation tree walker](code/cuppa2_interp_walk.py),\n",
    "```Python\n",
    "def walk(node):\n",
    "    # node format: (TYPE, [child1[, child2[, ...]]])\n",
    "    type = node[0]\n",
    "    \n",
    "    if type in dispatch_dict:\n",
    "        node_function = dispatch_dict[type]\n",
    "        return node_function(node)\n",
    "    else:\n",
    "        raise ValueError(\"walk: unknown tree node type: \" + type)\n",
    "\n",
    "# a dictionary to associate tree nodes with node functions\n",
    "dispatch_dict = {\n",
    "    'seq'     : seq,\n",
    "    'nil'     : nil,\n",
    "    'declare' : declare_stmt,\n",
    "    'assign'  : assign_stmt,\n",
    "    'get'     : get_stmt,\n",
    "    'put'     : put_stmt,\n",
    "    'while'   : while_stmt,\n",
    "    'if'      : if_stmt,\n",
    "    'block'   : block_stmt,\n",
    "    'integer' : integer_exp,\n",
    "    'id'      : id_exp,\n",
    "    'paren'   : paren_exp,\n",
    "    '+'       : plus_exp,\n",
    "    '-'       : minus_exp,\n",
    "    '*'       : times_exp,\n",
    "    '/'       : divide_exp,\n",
    "    '=='      : eq_exp,\n",
    "    '<='      : le_exp,\n",
    "    'uminus'  : uminus_exp,\n",
    "    'not'     : not_exp\n",
    "}\n",
    "```\n",
    "Notice that the dispatch dictionary associates the `declare` node with the `declare_stmt` node function,\n",
    "```Python\n",
    "def declare_stmt(node):\n",
    "\n",
    "    try: # try the declare pattern without initializer\n",
    "        (DECLARE, name, (NIL,)) = node\n",
    "        assert_match(DECLARE, 'declare')\n",
    "        assert_match(NIL, 'nil')\n",
    "\n",
    "    except ValueError: # try declare with initializer\n",
    "        (DECLARE, name, init_val) = node\n",
    "        assert_match(DECLARE, 'declare')\n",
    "        \n",
    "        value = walk(init_val)\n",
    "        state.symbol_table.declare_sym(name, value)\n",
    "\n",
    "    else: # declare pattern matched\n",
    "        # when no initializer is present we init with the value 0\n",
    "        state.symbol_table.declare_sym(name, 0)\n",
    "```\n",
    "The `declare_stmt` node function has to deal with two different flavors of the `declare` node: one with an initializer and one without one.  We can see that the node function first attempts to pattern match the `declare` node without an initializer by matching the `nil` tree node in the last argument.  If this pattern is successfully matched execution continues in the `else` clause of the [`try-except` Python statement](https://docs.python.org/3/tutorial/errors.html) where we declare the variable with a default initial value of 0 in the current scope in the symbol table.\n",
    "\n",
    "Python will throw an exception should the declaration pattern without the initializer fail to match.  In this case the code in the `except` clause of the [`try-except` Python statement](https://docs.python.org/3/tutorial/errors.html) will be executed.  Here we try to match the current AST node against a pattern that assumes we have an initializer.  If this pattern match is successful then we walk the expression tree of the initialization value computing an actual value which we then associate with the variable name during its declaration in the symbol table.\n",
    "\n",
    "We have other node functions impacted by the new scoping rules and the new symbol table structure.  We start with the assignment statement,\n",
    "```Python\n",
    "def assign_stmt(node):\n",
    "\n",
    "    (ASSIGN, name, exp) = node\n",
    "    assert_match(ASSIGN, 'assign')\n",
    "    \n",
    "    value = walk(exp)\n",
    "    state.symbol_table.update_sym(name, value)\n",
    "```\n",
    "What changed between in the `assign_stmt` function from Cuppa1 to Cuppa2 is the fact that in Cuppa2 variables have to be declared before you can assign values to them with the assignment statement.  Therefore the behavior of the assignment statement in Cuppa2 is an update rather than a symbol definition in a dictionary as in Cuppa1.  Furthermore, recall that that update can be a non-local update, that is, we are potentially updating a variable outside of our local scope.\n",
    "\n",
    "The next function we look at is the `get_stmt` function,\n",
    "```Python\n",
    "def get_stmt(node):\n",
    "\n",
    "    (GET, name) = node\n",
    "    assert_match(GET, 'get')\n",
    "\n",
    "    s = input(\"Value for \" + name + '? ')\n",
    "    \n",
    "    try:\n",
    "        value = int(s)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"expected an integer value for \" + name)\n",
    "    \n",
    "    state.symbol_table.update_sym(name, value)\n",
    "```\n",
    "Again we can see that it is the same function as in Cuppa1 with the exception that the symbol table performs an update rather than a symbol definition.\n",
    "\n",
    "The `block_stmt` function is interesting because here we explicitly manipulate the scope stack of the symbol table reflecting the fact that a block statement in Cuppa2 introduces a new scope,\n",
    "```Python\n",
    "def block_stmt(node):\n",
    "    \n",
    "    (BLOCK, stmt_list) = node\n",
    "    assert_match(BLOCK, 'block')\n",
    "    \n",
    "    state.symbol_table.push_scope()\n",
    "    walk(stmt_list)\n",
    "    state.symbol_table.pop_scope()\n",
    "```\n",
    "Here we push a new scope onto the scope stack in the symbol table just before we walk the statement list of the block statement.  Once we are done interpreting the statements within the block statement we pop the scope off the stack implementing the behavior we have intuitively used when we looked at the Cuppa2 programs at the beginning of this chapter.\n",
    "\n",
    "This only leaves the `id_exp` node function.  This function retrieves the value of a variable within an expression,\n",
    "```Python\n",
    "def id_exp(node):\n",
    "    \n",
    "    (ID, name) = node\n",
    "    assert_match(ID, 'id')\n",
    "    \n",
    "    return state.symbol_table.lookup_sym(name)\n",
    "```\n",
    "Again this function is identical to the function in Cuppa1 except that we have to deal with the fact that we might be trying to retrieve the value of a non-local variable, a variable not in our current scope.  Therefore this function uses the `lookup_sym` function from our scoped symbol table.\n",
    "\n",
    "All other node function remain identical to the node functions in Cuppa1.  Which in some sense is kind of remarkable and illustrates an interesting modularity in programming language design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we try our new interpreter we should mention that the [state object](code/cuppa2_state.py) in Cuppa2 is virtually identical to the state object in Cuppa1 except that it makes reference to the new scoped symbol table.\n",
    "\n",
    "Let's try our new interpreter on some of the programs we discussed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuppa2_lex import lexer\n",
    "from cuppa2_frontend import parser\n",
    "from cuppa2_state import state\n",
    "from cuppa2_interp_walk import walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the first program we discussed and according to our scoping rules the output should be the sequence `2 3 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2\n",
      "> 3\n",
      "> 1\n"
     ]
    }
   ],
   "source": [
    "program =\\\n",
    "'''\n",
    "// declare a global instance of x\n",
    "declare x = 1;\n",
    "\n",
    "// create a local block scope\n",
    "{\n",
    "    // declare a local instance of x\n",
    "    declare x = 2;\n",
    "    // print out the value of local instance\n",
    "    put x;\n",
    "}\n",
    "\n",
    "// create another local block scope\n",
    "{\n",
    "    // declare a local instance of x\n",
    "    declare x = 3;\n",
    "    // print out the value of local instance\n",
    "    put x;\n",
    "}\n",
    "\n",
    "// print out the value of the global instance\n",
    "put x;\n",
    "'''\n",
    "\n",
    "state.initialize()\n",
    "parser.parse(program, lexer=lexer)\n",
    "walk(state.AST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!\n",
    "\n",
    "The next program we discussed was a program with non-local variable access.  This program reads and updates the global variable `x` from within a nested local scope.  The expected output is the value `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 5\n"
     ]
    }
   ],
   "source": [
    "program =\\\n",
    "'''\n",
    "// declare global instance of x\n",
    "declare x = 2;\n",
    "\n",
    "// start a local scope\n",
    "{\n",
    "      declare y = 3;\n",
    "      // read and update non-local x\n",
    "      x = y + x;\n",
    "}\n",
    "\n",
    "// print out the updated value of x\n",
    "put x;\n",
    "\n",
    "'''\n",
    "\n",
    "state.initialize()\n",
    "parser.parse(program, lexer=lexer)\n",
    "walk(state.AST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our interpreter works as expected!\n",
    "\n",
    "Let's try one more.  This program reads the values of various local and non-local variables.  The expected output is `6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 6\n"
     ]
    }
   ],
   "source": [
    "program = \\\n",
    "'''\n",
    "declare x = 1;\n",
    "\n",
    "{\n",
    "    declare y = 2;\n",
    "\n",
    "    {\n",
    "        declare z = 3;\n",
    "        put x + y + z;\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "state.initialize()\n",
    "parser.parse(program, lexer=lexer)\n",
    "walk(state.AST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, just as expected!\n",
    "\n",
    "As we have done for Cuppa1 and our other languages we can wrap the lexing, parsing and tree walking into a convenient [`interp`  function](code/cuppa2_interp.py), which by the way looks identical to the `interp` function in Cuppa1 except that it of course references our new objects,\n",
    "\n",
    "```Python\n",
    "from cuppa2_lex import lexer\n",
    "from cuppa2_frontend import parser\n",
    "from cuppa2_state import state\n",
    "from cuppa2_interp_walk import walk\n",
    "\n",
    "def interp(input_stream):\n",
    "\n",
    "    # initialize the state object\n",
    "    state.initialize()\n",
    "\n",
    "    # build the AST\n",
    "    parser.parse(input_stream, lexer=lexer)\n",
    "\n",
    "    # walk the AST\n",
    "    walk(state.AST)\n",
    "```\n",
    "We can call this function to execute our Cuppa2 programs. Let's give it a try,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 1\n"
     ]
    }
   ],
   "source": [
    "from cuppa2_interp import interp\n",
    "\n",
    "program = \\\n",
    "'''\n",
    "declare x = 1\n",
    "put x\n",
    "'''\n",
    "\n",
    "interp(program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntactic vs. Semantic Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the programming languages we are developing here are becoming more complex we can observe that different classes of errors can happen within a program.  Two such classes are *syntactic* and *semantic* errors. We can define these classes of errors as follows,\n",
    "\n",
    "* Syntactic errors are errors that occur in the structure of a program such as a missing semicolon or a misspelled keyword.\n",
    "\n",
    "* Semantic errors are errors in the behavior of a program such as using a variable before it was declared.\n",
    "\n",
    "Syntactic errors can be detected and reported by the parser.  However, in contrast programs with semantic errors are usually syntactically correct.  That is the parser cannot detect these errors and we have to rely on other ways of detecting these errors.  In the case of Cuppa2 we used the symbol table to enforce some of the semantics or behavior rules of the language with regards to variable declarations.  \n",
    "\n",
    "A classic example of a semantic error  is the [division by zero](https://en.wikipedia.org/wiki/Division_by_zero) error.  It is a semantic error because in general it is not detectable by an interpreter or compiler at a parse time. In most programming languages a division by zero results in the termination of the program with an error.  An interpreter will detect this kind of error while executing a program.  However, what sets this error apart from for example, an undeclared variable error, is the fact that a compiler cannot detect this semantic error.  This kind of semantic error is due to a faulty calculation in the algorithm a program implements and since a compiler does not perform any computation but simply translates a program into a target language this faulty behavior is passed along to the translated program which will then terminate when this error occurs.\n",
    "\n",
    "Another classic example of a semantic error is the [`null` pointer dereference](https://en.wikipedia.org/wiki/Null_pointer) in C.  In C it is illegal to dereference a pointer variable whose value is 0 or `null`.  Doing so will result in a \"crash\" of the program.  However, it is impossible for a C compiler to flag such a dereference at compile time because it is usally the result of a mistake in the algorithm a program implements.  Since a compiler does not perform any computations but simply translates a source program it cannot detect these kinds of errors and again the faulty behavior is passed along to the translated program which will then \"crash\" when this error occurs.  \n",
    "\n",
    "Let's take a look at various syntactic and semantic errors.  The first program contains a misspelled keyword which can easily flagged by the parser,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syntax error at 'x'\n",
      "Error: x was not declared\n"
     ]
    }
   ],
   "source": [
    "program = \\\n",
    "'''\n",
    "define x = 1\n",
    "put x\n",
    "'''\n",
    "\n",
    "try:\n",
    "    interp(program)\n",
    "except Exception as e:\n",
    "    print(\"Error: \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the parser found the misspelled keyword on the first line of the program right before the variable `x`.  Our parser implementation considers syntax errors recoverable errors and therefore just flags them and keeps going.  Which brings us to the second error message above.  Since there was no legal declaration of the variable `x` its occurrence in the `put` statement is flagged as an error.  Our second program makes this explicit.  Here we insert a semantic error by using a variable without declaring it,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: y was not declared\n"
     ]
    }
   ],
   "source": [
    "program = \\\n",
    "'''\n",
    "declare x = 1\n",
    "put y + x\n",
    "'''\n",
    "\n",
    "try:\n",
    "    interp(program)\n",
    "except Exception as e:\n",
    "    print(\"Error: \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are dealing with a semantic error because the parser did not flag it as a syntactic error.  It is an error in the behavior of the program -- using the variable `y` without declaring it.  Again, the hallmark of semantic errors is that they occur in syntactically correct programs.\n",
    "\n",
    "Let's take a look at the *division by zero*  error in the Cuppa2 interpreter,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: integer division or modulo by zero\n"
     ]
    }
   ],
   "source": [
    "program = \\\n",
    "'''\n",
    "declare x = 0\n",
    "put 4 / x\n",
    "'''\n",
    "\n",
    "try:\n",
    "    interp(program)\n",
    "except Exception as e:\n",
    "    print(\"Error: \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, we find that the Cuppa1 compiler cannot detect this error and passes it along to the Exp1Bytecode virtual machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** compile code ****\n",
      "**** run code ****\n",
      "Error: integer division or modulo by zero\n"
     ]
    }
   ],
   "source": [
    "from cuppa1_cc import cc as cuppa1_compiler\n",
    "from exp1bytecode_interp import interp as bytecode_run\n",
    "\n",
    "program = \\\n",
    "'''\n",
    "x = 0\n",
    "put 4 / x\n",
    "'''\n",
    "\n",
    "print(\"**** compile code ****\")\n",
    "try:\n",
    "    bytecode = cuppa1_compiler(program)\n",
    "except Exception as e:\n",
    "    print(\"Error: \" + str(e))\n",
    "\n",
    "print(\"**** run code ****\")\n",
    "try:\n",
    "    bytecode_run(bytecode)\n",
    "except Exception as e:\n",
    "    print(\"Error: \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted, the compiler was not able to find the semantic error and passed it along to the abstract machine which found the error when it executed the translated Cuppa1 program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling Scoped Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling scoped code raises a set of issues because most low-level languages do not support scoping.  Since scoping is purely a high-level language construct restricting the visibility of symbols to make programs more robust, the compiler has to somehow simulate scoping in the low-level target language.  As we will see, an effective way to simulate scoping is by cleverly renaming variables so that variables with the same name in different scopes do not clash in the global scope of the target language.\n",
    "\n",
    "How the actual declarations of variables in the source language get mapped into the target language depends on the target language.\n",
    "In our case, where we are interested in building a compiler from the Cuppa2 language to Exp1bytecode, the declarations of variables in Cuppa2 just become assignment statements in our low-level target language.  In assembly code for actual machine language the declaration statements of a high-level language are typically mapped to *symbolic memory locations* of the target machine and these symbolic memory locations then serve as the variables in the assembly code. Whatever the precise mapping is, it is clear that variable declarations and scope are purely high-level language constructs and it is the job of the compiler to map those into appropriate low-level structures in the target language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"800\" height=\"600\" src=\"figures/chap07/2/figure.jpg\">\n",
    "</p>\n",
    "<p style=\"text-align: center;\">\n",
    "Fig. 2: Exp1Bytecode for a Cuppa2 program with only gobal variables.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration purposes let's take a look at a couple of examples where we map Cuppa2 programs into Exp1Bytecode. Figure 2 shows a Cuppa2 program that only declares global variables.  Scoping has no impact on the translation of this program into Exp1Bytecode and the translated program will execute correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"800\" height=\"600\" src=\"figures/chap07/3/figure.jpg\">\n",
    "</p>\n",
    "<p style=\"text-align: center;\">\n",
    "Fig. 3: Naively translating a Cuppa2 program with local scopes into Exp1Bytecode.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The situation changes drastically as soon as we introduce variables declared in local scopes in our Cuppa2 program it Figure 3. Here we  show the naive translation of such a program into Exp1Bytecode.  We have color coded the code according to scoping level: *red* for the global scope and *green* for the nested scope.  It is easy to see that the red `x` and the green `x` clash in the global scope of the target language.  Because of this clash the translated program generates incorrect output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"800\" height=\"600\" src=\"figures/chap07/4/figure.jpg\">\n",
    "</p>\n",
    "<p style=\"text-align: center;\">\n",
    "Fig. 4: Translating a Cuppa2 program with local scopes into Exp1Bytecode using variable name prefixes to simulate scope.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can restore the correct behavior of the translated program by renaming the variables in the translated program so that variables with the same name but declared in different scopes in the source language do not clash in the global scope of the target language.  Here we use a name prefix that is based on the scope where the variable was declared.   If the variable was declared in the global scope then it receives a prefix of `R$` in the target language.  If it was declared in a local scope at the first nesting level then it receives a prefix of `R$$`.  If the variable was declared in local scope at the second nesting level then it receives a prefix of `R$$$`, *etc.*  It doesn't really matter what the prefix is as long as it is easy to calculate in the compiler and does not clash with possible variable names of the source language.  Here we chose a prefix based on the `$` sign since this symbol cannot appear in a variable name in Cuppa2.\n",
    "\n",
    "Figure 4 shows a working translation of our previously problematic Cuppa2 program.  Notice that the two variables no longer clash in the target language and the correct behavior of the source program is restored in the translated program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"800\" height=\"600\" src=\"figures/chap07/5/figure.jpg\">\n",
    "</p>\n",
    "<p style=\"text-align: center;\">\n",
    "Fig. 5: Translating a program with multiple local scopes. \n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 5 illustrates the translation of a Cuppa2 program with multiple local scopes. This works because the two local scopes are at the same level and can never be active at the same time.  Therefore, it is safe to reuse the variable names due to the scoping.  The only caveat here is that you have to be careful that the variables are properly initialized before you use them in context of the second scope.  In our compiler we will always do that.  If no initializer exists for a local variable then we initialize the variable with the default value 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Cuppa2 Compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture for our Cuppa2 compiler shown in Figure 6 has the same architecture we used for our basic Cuppa1 compiler in Chapter 6.  We have a front end constructing our AST and we use a tree walker for our code generation phase.  Finally, the `output` module turns the generated instruction tuples into actual Exp1bytecode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"800\" height=\"600\" src=\"figures/chap07/6/figure.jpg\">\n",
    "</p>\n",
    "<p style=\"text-align: center;\">\n",
    "Fig. 6: Cuppa2 compiler architecture.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to reiterate, compilers do not compute values instead they validate the source program as much as they can, making sure that the syntactic structure and the intended behavior of the program are correct but they do not execute the program.  If the correctness of the source program is established a compiler generates code for the target machine that then executes it exhibiting the intended behavior such as computing values and interacting with the user among many other things.\n",
    "\n",
    "The fact that compilers do not compute values but validate the source program has an effect on the symbol table:\n",
    "rather than storing variable-value pairs the symbol table act merely as a record holder for variables seen/declared in order to enforce semantic rules such as *each variable has to be declared before its use*.\n",
    "In our case, it is convenient to use the symbol table to compute and store (name, target-name) pairs where the target-name is the name generated by adding a prefix such as our `R$$$` prefixes to indicate to which scope level a \n",
    "variable belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Symbol Table and Front End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned above, the symbol table in compilers does not hold (name, value) pairs but instead is used to validate declarations of variables throughout the program.  In our case we will also use the symbol table to compute and store our name prefixes for Exp1Bytecode variable names.  Here is the [Cuppa2 symbol table](code/cuppa2_cc_symtab.py) modified for our purposes,\n",
    "```Python\n",
    "class SymTab:\n",
    "\n",
    "    #-------\n",
    "    def __init__(self):\n",
    "        …\n",
    "    #-------\n",
    "    def push_scope(self):\n",
    "        # push a new dictionary onto the stack - stack grows to the left\n",
    "        …\n",
    "    #-------\n",
    "    def pop_scope(self):\n",
    "        # pop the left most dictionary off the stack\n",
    "        …\n",
    "    #-------\n",
    "    def declare_sym(self, sym):\n",
    "        # declare the symbol in the current scope: dict @ position 0\n",
    "        \n",
    "        # first we need to check whether the symbol was already declared\n",
    "        # at this scope\n",
    "        if sym in self.scoped_symtab[CURR_SCOPE]:\n",
    "            raise ValueError(\"symbol {} already declared\".format(sym))\n",
    "        \n",
    "        # enter the symbol in the current scope\n",
    "        n_scopes = len(self.scoped_symtab)\n",
    "        prefix = create_prefix(n_scopes-1)\n",
    "        scope_dict = self.scoped_symtab[CURR_SCOPE]\n",
    "        scope_dict[sym] = prefix + sym # value is the prefixed name\n",
    "\n",
    "    #-------\n",
    "    def lookup_sym(self, sym):\n",
    "        # find the first occurrence of sym in the symtab stack\n",
    "        # and return the associated value\n",
    "        …\n",
    "```\n",
    "Notice that we no longer have an `update_sym` function.  This function is superfluous in the context of a compiler since it does not compute values.  Furthermore, notice that declaring a symbol no longer requires a value but instead the function `declare_sym` computes a prefix based on the current scoping level and uses it as a value in the (name, value) pair in the symbol table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [compiler front end](code/cuppa2_cc_frontend.py) is the same front end we used for the interpreter with the exception that here we need to include the [compiler state object](code/cuppa2_cc_state.py) which in turn uses the new symbol table from above.  The compiler front end generates the same AST as the interpreter front end,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuppa2_lex import lexer\n",
    "from cuppa2_cc_frontend import parser\n",
    "from cuppa2_cc_state import state\n",
    "from grammar_stuff import dump_AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(seq \n",
      "  |(declare x \n",
      "  |  |(integer 1)) \n",
      "  |(seq \n",
      "  |  |(put \n",
      "  |  |  |(id x)) \n",
      "  |  |(nil)))\n"
     ]
    }
   ],
   "source": [
    "parser.parse(\"declare x = 1; put x\", lexer=lexer)\n",
    "dump_AST(state.AST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Code Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the compiler is based on the Cuppa1 compiler we can use most of that code generator but we need to modify the code generation tree walker for declaration, get, and assignment statements as well as for variables that can appear in expressions.  This is not unlike the modifications we had to make to the interpretation tree walker for our Cuppa2 interpreter.  Here is the node function that deals with variable declaration AST nodes,\n",
    "```Python\n",
    "def declare_stmt(node):\n",
    "    \n",
    "    try: # try the declare pattern without initializer\n",
    "        (DECLARE, name, (NIL,)) = node\n",
    "        assert_match(DECLARE, 'declare')\n",
    "        assert_match(NIL, 'nil')\n",
    "    \n",
    "    except ValueError: # try declare with initializer\n",
    "        (DECLARE, name, init_val) = node\n",
    "        assert_match(DECLARE, 'declare')\n",
    "        \n",
    "        state.symbol_table.declare_sym(name)\n",
    "        scoped_name = state.symbol_table.lookup_sym(name)\n",
    "        value = walk(init_val)\n",
    "        code = [('store', scoped_name, str(value))]\n",
    "\n",
    "        return code\n",
    "\n",
    "    else: # declare pattern matched\n",
    "        # when no initializer is present we init with the value 0\n",
    "        state.symbol_table.declare_sym(name)\n",
    "        scoped_name = state.symbol_table.lookup_sym(name)\n",
    "\n",
    "        code = [('store', scoped_name, '0')]\n",
    "\n",
    "        return code\n",
    "```\n",
    "As we have seen when we developed the interpreter `declare` nodes come in two flavors: with and without an initializer.  The interesting part here is that both flavors of the declaration statements are translated into `store` statements in the target language.  Note that we declare a symbol in the symbol table to make it known that that symbol was declared at the source language level.  We need to do that in order to be able to enforce the a *variable needs to be declared before using it* semantic rule.  However, right after declaring the symbol we turn around and ask the symbol table for the associated translated name which now has the scope prefix attached to it.  We use this translated name to generate the `store` instruction tuple.\n",
    "\n",
    "In assignment and get statements the `lookup_sym` serves double duty as well. By looking up a symbol we enforce the rule that a symbol needs to be declared before use and we also retrieve the translated name of the symbol at the same time. Here are the two relevant node functions,\n",
    "```Python\n",
    "def assign_stmt(node):\n",
    "\n",
    "    (ASSIGN, name, exp) = node\n",
    "    assert_match(ASSIGN, 'assign')\n",
    "    \n",
    "    exp_code = walk(exp)\n",
    "    scoped_name = state.symbol_table.lookup_sym(name)\n",
    "    code = [('store', scoped_name, exp_code)]\n",
    "    \n",
    "    return code\n",
    "\n",
    "```\n",
    "and,\n",
    "```Python\n",
    "def get_stmt(node):\n",
    "\n",
    "    (GET, name) = node\n",
    "    assert_match(GET, 'get')\n",
    "\n",
    "    scoped_name = state.symbol_table.lookup_sym(name)\n",
    "    code = [('input', scoped_name)]\n",
    "\n",
    "    return code\n",
    "```\n",
    "As we can see, assignment statements are mapped into `store` instructions and get statements are mapped into `input` instructions in the identical way as we have seen in the Cuppa1 compiler with the exception that now we use the translated name in the target code rather than the source language name.\n",
    "\n",
    "The leaves variable in expressions to look at.  Here is the node function for variables that can appear in expressions,\n",
    "```Python\n",
    "def id_exp(node):\n",
    "    \n",
    "    (ID, name) = node\n",
    "    assert_match(ID, 'id')\n",
    "    \n",
    "    scoped_name = state.symbol_table.lookup_sym(name)\n",
    "    \n",
    "    return scoped_name\n",
    "\n",
    "```\n",
    "This node function simply maps the source name of a variable into the translated name of the variable and again enforces that fact that variables need to be declared before use.  The remainder of the code generator remains unchanged with the exception that we need to insert the `declare_stmt` node function into the dispatch dictionary in an appropriate way. The file [`cuppa2_cc_codegen.py`](code/cuppa2_cc_codegen.py) contains the full code generator.\n",
    "\n",
    "The [output phase](code/cuppa2_cc_output.py) is exactly the same as the Cuppa1 output phase, but in order to keep things simple we deleted the peephole optimization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some final thoughts on the Cuppa2 compiler before we move on to testing it. The difference between the Cuppa1 and Cuppa2 languages is the introduction of scope and variable declarations. These are purely high-level language constructs and we see this manifested in that the only thing that really changed in the Cuppa2 compiler compared to the Cuppa1 compiler is how variables are named!\n",
    "That means the Cuppa2 compiler is completely responsible for enforcing scope it cannot pass that through to the underlying abstract machine since this machine has no concept of scope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuppa2_cc import cc as cuppa2_compiler\n",
    "from exp1bytecode_interp import interp as bytecode_run\n",
    "from cuppa2_examples import scope1, scope2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "declare x = 1;\n",
      "{\n",
      "    declare x = 2;\n",
      "    put x;\n",
      "}\n",
      "{\n",
      "    declare x = 3;\n",
      "    put x;\n",
      "}\n",
      "put x;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scope1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the semantics of the Cuppa2 language the expected output for the program is,\n",
    "```\n",
    "2\n",
    "3\n",
    "1\n",
    "```\n",
    "Let's see if we can replicate that.  First, let's look at the translated code,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tstore R$x 1 ;\n",
      "\tstore R$$x 2 ;\n",
      "\tprint R$$x ;\n",
      "\tstore R$$x 3 ;\n",
      "\tprint R$$x ;\n",
      "\tprint R$x ;\n",
      "\tstop ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bytecode = cuppa2_compiler(scope1)\n",
    "print(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks reasonable and running the code in the abstract machine gives us,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2\n",
      "> 3\n",
      "> 1\n"
     ]
    }
   ],
   "source": [
    "bytecode_run(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly what we expected!  Let's try the other program,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "declare x = 1;\n",
      "put x;\n",
      "{\n",
      "    x = 2;\n",
      "}\n",
      "put x;\n",
      "{\n",
      "    x = 3;\n",
      "}\n",
      "put x;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scope2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we expect the output to be,\n",
    "```\n",
    "1\n",
    "2\n",
    "3\n",
    "```\n",
    "Running the compiler and the abstract machine,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tstore R$x 1 ;\n",
      "\tprint R$x ;\n",
      "\tstore R$x 2 ;\n",
      "\tprint R$x ;\n",
      "\tstore R$x 3 ;\n",
      "\tprint R$x ;\n",
      "\tstop ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bytecode = cuppa2_compiler(scope2)\n",
    "print(bytecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 1\n",
      "> 2\n",
      "> 3\n"
     ]
    }
   ],
   "source": [
    "bytecode_run(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly what we expected! That means our compiler implements scoping correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every modern programming language has some notion of scope in order to limit the visibility of symbols within programs.  Here we designed our Cuppa2 language by extending the Cuppa1 language with the `declare` statement allowing us declare variables in specific scopes and by allowing block statements to introduce new scope levels.  In order to support scoping properly we added functionality to our symbol table mechanism in the form of a stack of dictionaries.  As we saw, this works very well since nested scopes can be modeled nicely via a stack.  We built  a Cuppa2 interpreter and a compiler both loosely based on their Cuppa1 equivalents.  It was interesting to observe that we only had to modify the code directly affected by the language design change.  In addition we had to address specific challenges when compiling scoped code since in most cases the target language does not support any kind of scoping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps one of the earliest references to block structure and scope in programming language design can be found in C.A.R. Hoare's paper,\n",
    "\n",
    "Hoare, C. A. (1973). [*Hints on programming language design*](http://i.stanford.edu/pub/cstr/reports/cs/tr/73/403/CS-TR-73-403.pdf). (No. STAN-CS-73-403). STANFORD UNIV CA DEPT OF COMPUTER SCIENCE.\n",
    "\n",
    "Kernighan and Ritchie describe the block structure and the effect of variable shadowing (hiding) in section 4.8 in their classic C programming language book,\n",
    "\n",
    "Kernighan, B. W., Ritchie, D. M. (1988). *The C Programming Language, 2nd Edition*. Prentice-Hall software series.\n",
    "\n",
    "This is perhaps interesting because the block structure design of our Cuppa family of languages is loosely based on their ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a Cuppa2 compiler that translates Cuppa2 programs into your favorite programming language. Can you take advantage of scoping rules in the target language?\n",
    "\n",
    "1. Design and implement a programming language of your own choosing that also supports scoping.\n",
    "\n",
    "1. Write a Cuppa2 compiler that translates Cuppa2 programs into Java virtual machine code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
