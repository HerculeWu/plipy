{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Compilers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilers are programs that translate programs written in one language to the same program written in another, most often, lower level language.  We often refer to the languages as source and target language, respectively.  Optimizing compilers are multiphase language processors with explicit code optimization phases in addition to the  code generation, syntax, and program analysis phases mentioned in Chapter 1. Here we discuss an optimizing compiler for our Cuppa1 language.  The source language for our compiler is the Cuppa1 language and the target language is our Exp1bytecode.  It is an optimizing compiler because the compiler performs constant folding and peephole optimizations in order to improve the generated code.\n",
    "\n",
    "We start our discussion by looking at the basic compiler that translates Cuppa1 programs into Exp1bytecode.  As soon as we have a compiler this raises the question of compiler correctness.  Here we look at compiler correctness in context of our Cuppa1 interpreter from Chapter 5. The last part of the current chapter is dedicated to looking at optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let the notebook access the code folder\n",
    "import sys\n",
    "sys.path.insert(1,\"code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Basic Compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a fundamental level compilers can be understood as processors that match AST patterns of the source language and translate them into patterns in the target language.  Recall the AST construction in the [Cuppa1 frontend](code/cuppa1_frontend_gram.py) and consider for example the AST pattern for the assignment statement in Cuppa1,\n",
    "```\n",
    "('assign', name, exp)\n",
    "```\n",
    "We could easily envision translating this AST pattern into a pattern in [Exp1bytecode](code/exp1bytecode_gram.py) as follows,\n",
    "```\n",
    "store <name> <exp>;\n",
    "```\n",
    "where `<name>` and `<exp>` are the appropriate translations of the variable name and the assignment expression from Cuppa1 into Exp1bytecode.  Here the target pattern is just a single instruction. However, the more complicated AST patterns in the source language the more complicated the target patterns as we will see when we look at programming constructs such as the while loop.\n",
    "\n",
    "In our case it is not that difficult to come up with pattern translations for all the non-structured statements and expressions in Cuppa1. For all the non-structured statements we have the pattern translations,\n",
    "```\n",
    "('assign', name, exp) => store <name> <exp>;\n",
    "('put', exp) => print <exp>;\n",
    "('get', name) => input <name>;\n",
    "```\n",
    "And for the expressions we have,\n",
    "```\n",
    "('+', c1, c2) => ('+' <c1> <c2>)\n",
    "('-', c1, c2) => ('-' <c1> <c2>)\n",
    "('*', c1, c2) => ('*' <c1> <c2>)\n",
    "('/', c1, c2) => ('/' <c1> <c2>)\n",
    "('==', c1, c2) => ('==' <c1> <c2>)\n",
    "('<=', c1, c2) => ('<=' <c1> <c2>)\n",
    "('id', name) => <name>\n",
    "('integer', value) => <value>\n",
    "('uminus', value) => - <value>\n",
    "('not', value) => ! <value>\n",
    "```\n",
    "In order to come up with a pattern translation for structured statements such as the while statement we have to be clear what the behavior\n",
    "of the while statement `while (cond) body` is:  Evaluate the condition `cond` and execute the `body` as long as the condition evaluates to a value not equal to zero.  If the condition ever evaluates to zero then ignore the body of the loop and continue execution right after the loop.  We can simulate this behavior in Exp1bytecode with jump instructions. One way to translate the AST pattern for the while loop into a code pattern in Exp1bytecode is,\n",
    "```\n",
    "('while', cond, body) => Ltop:\n",
    "                             jumpF <cond> Lbottom;\n",
    "                             <body>\n",
    "                             jump Ltop; \n",
    "                         Lbottom:\n",
    "                             noop;\n",
    "```\n",
    "Here `Ltop` and `Lbottom` are labels. We can easily verify that the Exp1bytecode pattern simulates exactly the behavior of the Cuppa1 while statement: If the condition evaluates to something other than zero then execute the body of the loop and then jump to the top of the loop in order to reevaluate the condition.  If the condition ever evaluates to zero then the `jumpF` instruction will transfer control to the `Lbottom` label. That is, if the condition evaluates to zero then we skip the loop body and continue executing the statement after the loop.  We have to have the `noop` instruction here because label definitions have to be attached to instructions.\n",
    "\n",
    "We can do something similar with if-then statements,\n",
    "```\n",
    "('if', cond, then_stmt, ('nil',)) =>     jumpF <cond> Lbottom;\n",
    "                                         <then_stmt>\n",
    "                                     Lbottom:\n",
    "                                         noop;\n",
    "```\n",
    "A closer look at the Exp1bytecode pattern shows that it simulates the behavior of the Cuppa1 if-then statement: If the condition evaluates to a non-zero value then we execute the then-statement.  Otherwise, if the condition evaluates to zero we ignore the then-statement by jumping to the `Lbottom` label and continue execution after the if-then statement.  Finally, adding the else-statement to the if-then statement we have,\n",
    "```\n",
    "('if', cond, then_stmt, else_stmt) =>     jumpF <cond> Lelse;\n",
    "                                          <then_stmt>\n",
    "                                          jump Lbottom;\n",
    "                                      Lelse: \n",
    "                                          <else_stmt>\n",
    "                                      Lbottom:\n",
    "                                         noop;\n",
    "```\n",
    "It is not difficult to see that the Exp1bytecode pattern similuates the behavior of the Cuppa1 if-then-else statement:  If the condition evaluates to a non-zero value then execute the then-statement and ignore the else-statement.  If the condition evaluates to zero ignore the then-statement and execute the else-statement.\n",
    "\n",
    "One thing to keep in mind is the notion of *target pattern compositionality*.  By that we mean that any target language patterns generated from the same class of AST patterns should be able to be composed.  Consider for example the statements in Cuppa1.  Any one of the Exp1bytecode patterns due to statements in Cuppa1 should be able to be composed with any other Exp1bytecode pattern due to a statement without ever generating incorrect target code.  The same thing is true for Exp1bycode patterns generated from Cuppa1 expressions: Any Exp1bytecode pattern generated from a Cuppa1 expression should be composable with any other Exp1bytecode pattern due to a Cuppa1 expression and alway give rise to valid Exp1bytecode expressions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A Code Generation Tree Walker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the Cuppa1 frontend generates an AST for a source program and according to what we said above we need to find patterns in this AST that match the patterns in our translations rules in order to generate target code.  Consider the following Cuppa1 program for which the frontend generates a corresponding AST,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuppa1_lex import lexer\n",
    "from cuppa1_frontend_gram import parser\n",
    "from cuppa1_state import state\n",
    "from grammar_stuff import dump_AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = \\\n",
    "'''\n",
    "get x\n",
    "x = x + 1\n",
    "put x\n",
    "'''\n",
    "parser.parse(program, lexer=lexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(seq \n",
      "  |(get x) \n",
      "  |(seq \n",
      "  |  |(assign x \n",
      "  |  |  |(+ \n",
      "  |  |  |  |(id x) \n",
      "  |  |  |  |(integer 1))) \n",
      "  |  |(seq \n",
      "  |  |  |(put \n",
      "  |  |  |  |(id x)) \n",
      "  |  |  |(nil))))\n"
     ]
    }
   ],
   "source": [
    "dump_AST(state.AST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to see that the left side patterns for our three pattern translation rules,\n",
    "```\n",
    "('get', name) => input <name>;\n",
    "('assign', name, exp) => store <name> <exp>;\n",
    "('put', exp) => print <exp>;\n",
    "```\n",
    "are present in the AST above.  In order to generate code we need to find those left side patterns in the AST and then apply the rules. Therefore,\n",
    "\n",
    "> The code generator for our compiler is a tree walker that walks the Cuppa1 AST and for each AST pattern that appears in a pattern translation rule it will generate the corresponding target code.\n",
    "\n",
    "There are two additional design choices that we make: \n",
    "\n",
    ">Cuppa1 statement patterns will generate Exp1bytecode instructions on a *list* and Cuppa1 expression patterns will generated Exp1bytecode expressions returned as *strings*.\n",
    "\n",
    "The reason for this will become clear later when we look at optimizations in this compiler. Let's take a look at some of the actual pattern translations.  A good place to start is the get statement,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuppa1_cc_codegen import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s get_stmt code/cuppa1_cc_codegen.py\n",
    "def get_stmt(node):\n",
    "\n",
    "    (GET, name) = node\n",
    "    assert_match(GET, 'get')\n",
    "\n",
    "    code = [('input', name)]\n",
    "\n",
    "    return code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our code generator is a tree walker what we are looking at is the node function for get nodes in the AST.  The function first pattern matches the get node.  It then generates the target code pattern in for an instruction tuple in a list.  The instruction tuple we are generating is not unlike the instruction tuple we used to represent programs with in the Exp1bytecode abstract machine in Chapter 4.  The list with the single Exp1bytecode instruction is then returned in order to be combined with other lists of instructions.  Even though the translation rule for the get statement demands that we also generate the semicolon as part of the translation,\n",
    "```\n",
    "('get', name) => input <name>;\n",
    "```\n",
    "we delay this until we  generate the actual machine instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s assign_stmt code/cuppa1_cc_codegen.py\n",
    "def assign_stmt(node):\n",
    "\n",
    "    (ASSIGN, name, exp) = node\n",
    "    assert_match(ASSIGN, 'assign')\n",
    "    \n",
    "    exp_code = walk(exp)\n",
    "\n",
    "    code = [('store', name, exp_code)]\n",
    "    \n",
    "    return code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The node function for assignment statements works in a very similar fashion.  It first pattern matches the node. Then it walks the expression AST which will return a string containing the Exp1bytecode for the Cuppa1 expression.  We now have all the pieces we need to assemble the target pattern according to our translation rule,\n",
    "```\n",
    "('assign', name, exp) => store <name> <exp>;\n",
    "```\n",
    "Here `<name>` is the name of the variable stored in variable `name` and `<exp>` is the Exp1bytecode expression string stored in the variable `exp_code` in the Python code above.  Now it is straight forward to create a tuple to represent the store instruction where the first component is the string `'store'`.  We put this tuple in a list which we return as the result of this translation. \n",
    "\n",
    "It is easy to see that the node function for the put statement,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s put_stmt code/cuppa1_cc_codegen.py\n",
    "def put_stmt(node):\n",
    "\n",
    "    (PUT, exp) = node\n",
    "    assert_match(PUT, 'put')\n",
    "    \n",
    "    exp_code = walk(exp)\n",
    "\n",
    "    code = [('print', exp_code)]\n",
    "\n",
    "    return code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implements the translation rule,\n",
    "```\n",
    "('put', exp) => print <exp>;\n",
    "```\n",
    "The node function for the structured while statement looks like this,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s while_stmt code/cuppa1_cc_codegen.py\n",
    "def while_stmt(node):\n",
    "    \n",
    "    (WHILE, cond, body) = node\n",
    "    assert_match(WHILE, 'while')\n",
    "    \n",
    "    top_label = label()\n",
    "    bottom_label = label()\n",
    "    cond_code = walk(cond)\n",
    "    body_code = walk(body)\n",
    "\n",
    "    code = [(top_label + ':',)]\n",
    "    code += [('jumpF', cond_code, bottom_label)]\n",
    "    code += body_code\n",
    "    code += [('jump', top_label)]\n",
    "    code += [(bottom_label + ':',)]\n",
    "    code += [('noop',)]\n",
    "\n",
    "    return code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is probably not that difficult to figure out that this node function implements the pattern translation rule for while loops,\n",
    "```\n",
    "('while', cond, body) => Ltop:\n",
    "                             jumpF <cond> Lbottom;\n",
    "                             <body>\n",
    "                             jump Ltop; \n",
    "                         Lbottom:\n",
    "                             noop;\n",
    "```\n",
    "Here the function `label()` generates a unique label name every time it is called.  A closer look at the [tree walker code](code/cuppa1_cc_codegen.py) will reveal that the node function for both variants of the if statement also generates the appropriate target code patterns.\n",
    "\n",
    "What remains to be looked at is how the tree walker deals with `seq` nodes since they act as the glue between the statements in the AST we saw above.  Related to this is how the walker deals with `nil` nodes in a statement sequence since `seq` sequences are `nil` terminated.  Here are the two respective node functions,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s seq,nil code/cuppa1_cc_codegen.py\n",
    "def seq(node):\n",
    "\n",
    "    (SEQ, s1, s2) = node\n",
    "    assert_match(SEQ, 'seq')\n",
    "    \n",
    "    stmt = walk(s1)\n",
    "    lst = walk(s2)\n",
    "\n",
    "    return stmt + lst\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "def nil(node):\n",
    "    \n",
    "    (NIL,) = node\n",
    "    assert_match(NIL, 'nil')\n",
    "    \n",
    "    return []\n",
    "    \n",
    "#########################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After matching the node the `seq` node function first walks the statement which according to our design decision will return a list of Exp1bytecode instructions.  Then the node function will walk the rest of the program which will return a list of all the Exp1bytecode instructions the rest of the program generated.  The instructions of the current statement are then *prependended* to the list of instructions generated by the rest of the program giving us a list of instructions from the current statement all the way to the end of the program.  This list is returned as the result of the `seq` node function.\n",
    "\n",
    "The `nil` node function simply returns an empty list.  Which is exactly what we want since `seq` sequences are `nil` terminated.\n",
    "\n",
    "Consider our AST from above,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(seq \n",
      "  |(get x) \n",
      "  |(seq \n",
      "  |  |(assign x \n",
      "  |  |  |(+ \n",
      "  |  |  |  |(id x) \n",
      "  |  |  |  |(integer 1))) \n",
      "  |  |(seq \n",
      "  |  |  |(put \n",
      "  |  |  |  |(id x)) \n",
      "  |  |  |(nil))))\n"
     ]
    }
   ],
   "source": [
    "dump_AST(state.AST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the tree walker walks the tree from top to bottom it will generate the following list(s),\n",
    "```\n",
    "[('input', 'x')] + \n",
    "    [('store', 'x', '(+, x , 1)')] +\n",
    "        [('print', 'x')] +\n",
    "            []\n",
    "```\n",
    "which is the same as the concatenated list,\n",
    "```\n",
    "[('input', 'x'),\n",
    " ('store', 'x', '(+ x 1)'),\n",
    " ('print', 'x')]\n",
    "```\n",
    "That is, the result of the tree walk is a list of instructions that represent the original program in Exp1bytecode.\n",
    "\n",
    "In order to understand the generation of the `assig` and `print` instruction fully we need to take a look at the translation of expressions.  Here are the main node functions, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s binop_exp,id_exp,integer_exp code/cuppa1_cc_codegen.py\n",
    "def binop_exp(node):\n",
    "\n",
    "    (OP, c1, c2) = node\n",
    "    if OP not in ['+', '-', '*', '/', '==', '<=']:\n",
    "        raise ValueError(\"pattern match failed on \" + OP)\n",
    "    \n",
    "    lcode = walk(c1)\n",
    "    rcode = walk(c2)\n",
    "\n",
    "    code = '(' + OP + ' ' + lcode + ' ' + rcode + ')'\n",
    "\n",
    "    return code\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "def id_exp(node):\n",
    "    \n",
    "    (ID, name) = node\n",
    "    assert_match(ID, 'id')\n",
    "    \n",
    "    return name\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "def integer_exp(node):\n",
    "\n",
    "    (INTEGER, value) = node\n",
    "    assert_match(INTEGER, 'integer')\n",
    "\n",
    "    return str(value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we had said earlier, expressions generate strings.  We clearly see this when we look at the node function for binary operators `binop_exp`.  The function walks the two children which in turn generates an expression string for each child and then synthesizes a string the represents the current binary operation.  This string is the return value of this node function.  The node function of `id_exp`, that is variable names that appear in expressions, returns the name of the variable and the node function of `integer_exp` return the value of the integers as a string.  In this way we can explain the expression string `'(+ x 1)'` that appears in the `store` instruction in our generated list of instructions.\n",
    "\n",
    "The code for the whole [tree walker code](code/cuppa1_cc_codegen.py).\n",
    "\n",
    "<!-- TODO: movie for the codegen tree walker -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting the Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code generator generates a set of Exp1bytecode instruction tuples for a Cuppa1 program.  In order to generate code that can be executed by the Exp1bytecode abstract machine we need to turn this list of instruction tuples into actual Exp1bytecode instructions.  This is easily accomplished by traversing the list and printing out the tuples in a nice formatted way.  The following function takes a list of tuples and returns a string with the nicely formatted Exp1bytecode instructions,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s output,label_def code/cuppa1_cc_output.py\n",
    "def output(instr_stream):\n",
    "\n",
    "    output_stream = ''\n",
    "    \n",
    "    for instr in instr_stream:\n",
    "\n",
    "        if label_def(instr):  # label def - print without preceeding '\\t' or trailing ';'\n",
    "            output_stream += instr[0] + '\\n'\n",
    "\n",
    "        else:                 # regular instruction - indent and put a ';' at the end\n",
    "            output_stream += '\\t'\n",
    "                \n",
    "            for component in instr:\n",
    "                output_stream += component + ' '\n",
    "\n",
    "            output_stream += ';\\n'\n",
    "\n",
    "    return output_stream\n",
    "\n",
    "#########################################################################\n",
    "def label_def(instr_tuple):\n",
    "\n",
    "    instr_name = instr_tuple[0]\n",
    "    \n",
    "    if instr_name[-1] == ':':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function iterates over the instruction tuples in the `instr_stream` and if the tuple is a label definition it will output it flush to the left margin, otherwise it will put a tab character in the output stream and then output the components of the current instruction tuple.  Consider our instruction list from before with a label to mark its start,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lstart:\n",
      "\tinput x ;\n",
      "\tstore x (+ x 1) ;\n",
      "\tprint x ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instr_stream = \\\n",
    "[('Lstart:',),\n",
    " ('input', 'x'),\n",
    " ('store', 'x', '(+ x 1)'),\n",
    " ('print', 'x')]\n",
    "\n",
    "bytecode = output(instr_stream)\n",
    "\n",
    "print(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like legal Exp1bytecode, let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp1bytecode_interp import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a value for x: 3\n",
      "> 4\n"
     ]
    }
   ],
   "source": [
    "interp(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK! Our output function generates legal code from a list of instruction tuples.  Let's put this all together into an actual compiler and then test it again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1 shows the architecture of our basic Cuppa1 compiler.  We can identify the frontend that generates the AST, the tree walker that generates the instruction tuples, and the output function that converts the instruction tuples into legal Exp1bytecode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figures/chap06/1/figure/Slide1.jpg)\n",
    "<p style=\"text-align: center;\">\n",
    "Fig. 1: Architecture of our basic Cuppa1 compiler.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put this compiler through its paces.  We do this by running the individual components separately so that we can see what's going on between each phase.  We start with the simple Cuppa1 program we looked at above.  But first we have load our prerequisite modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuppa1_lex import lexer\n",
    "from cuppa1_frontend_gram import parser\n",
    "from cuppa1_state import state\n",
    "from grammar_stuff import dump_AST\n",
    "from cuppa1_cc_codegen import walk as codegen\n",
    "from cuppa1_cc_output import output\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = \\\n",
    "'''\n",
    "get x\n",
    "x = x + 1\n",
    "put x\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the frontend,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(seq \n",
      "  |(get x) \n",
      "  |(seq \n",
      "  |  |(assign x \n",
      "  |  |  |(+ \n",
      "  |  |  |  |(id x) \n",
      "  |  |  |  |(integer 1))) \n",
      "  |  |(seq \n",
      "  |  |  |(put \n",
      "  |  |  |  |(id x)) \n",
      "  |  |  |(nil))))\n"
     ]
    }
   ],
   "source": [
    "parser.parse(program, lexer=lexer)\n",
    "dump_AST(state.AST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code generator,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('input', 'x'),\n",
      " ('store', 'x', '(+ x 1)'),\n",
      " ('print', 'x')]\n"
     ]
    }
   ],
   "source": [
    "instr_tuples = codegen(state.AST)\n",
    "pprint(instr_tuples, width = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the output formatter,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tinput x ;\n",
      "\tstore x (+ x 1) ;\n",
      "\tprint x ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bytecode = output(instr_tuples)\n",
    "print(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try something that has a structured programming statement in it.  How about the program that loops forever and does nothing?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "program = 'while (1) {}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(seq \n",
      "  |(while \n",
      "  |  |(integer 1) \n",
      "  |  |(block \n",
      "  |  |  |(nil))) \n",
      "  |(nil))\n"
     ]
    }
   ],
   "source": [
    "parser.parse(program, lexer=lexer)\n",
    "dump_AST(state.AST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our code generator does with AST,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('L0:',),\n",
      " ('jumpF', '1', 'L1'),\n",
      " ('jump', 'L0'),\n",
      " ('L1:',),\n",
      " ('noop',)]\n"
     ]
    }
   ],
   "source": [
    "instr_tuples = codegen(state.AST)\n",
    "pprint(instr_tuples, width = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's probably easier to read when it is properly formatted as Exp1bytecode,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L0:\n",
      "\tjumpF 1 L1 ;\n",
      "\tjump L0 ;\n",
      "L1:\n",
      "\tnoop ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bytecode = output(instr_tuples)\n",
    "print(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the loop will only terminate if the expression 1 ever evaluates to 0 -- which of course will never happen -- so it loops forever: jumping to `L0`, testing whether the expression 1 evaluates to 0, jumping to `L0`, testing...\n",
    "\n",
    "For our final example we'll look at something more complicated, the `fact` program from the Cuppa1 examples,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "get x;\n",
      "y = 1;\n",
      "while (1 <= x)\n",
      "{\n",
      "      y = y * x;\n",
      "      x = x - 1;\n",
      "}\n",
      "put y;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cuppa1_examples import fact\n",
    "print(fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the frontend,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(seq \n",
      "  |(get x) \n",
      "  |(seq \n",
      "  |  |(assign y \n",
      "  |  |  |(integer 1)) \n",
      "  |  |(seq \n",
      "  |  |  |(while \n",
      "  |  |  |  |(<= \n",
      "  |  |  |  |  |(integer 1) \n",
      "  |  |  |  |  |(id x)) \n",
      "  |  |  |  |(block \n",
      "  |  |  |  |  |(seq \n",
      "  |  |  |  |  |  |(assign y \n",
      "  |  |  |  |  |  |  |(* \n",
      "  |  |  |  |  |  |  |  |(id y) \n",
      "  |  |  |  |  |  |  |  |(id x))) \n",
      "  |  |  |  |  |  |(seq \n",
      "  |  |  |  |  |  |  |(assign x \n",
      "  |  |  |  |  |  |  |  |(- \n",
      "  |  |  |  |  |  |  |  |  |(id x) \n",
      "  |  |  |  |  |  |  |  |  |(integer 1))) \n",
      "  |  |  |  |  |  |  |(nil))))) \n",
      "  |  |  |(seq \n",
      "  |  |  |  |(put \n",
      "  |  |  |  |  |(id y)) \n",
      "  |  |  |  |(nil)))))\n"
     ]
    }
   ],
   "source": [
    "parser.parse(fact, lexer=lexer)\n",
    "dump_AST(state.AST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for the code generator,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('input', 'x'),\n",
      " ('store', 'y', '1'),\n",
      " ('L2:',),\n",
      " ('jumpF', '(<= 1 x)', 'L3'),\n",
      " ('store', 'y', '(* y x)'),\n",
      " ('store', 'x', '(- x 1)'),\n",
      " ('jump', 'L2'),\n",
      " ('L3:',),\n",
      " ('noop',),\n",
      " ('print', 'y')]\n"
     ]
    }
   ],
   "source": [
    "instr_tuples = codegen(state.AST)\n",
    "pprint(instr_tuples, width=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting the Exp1bytecode,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tinput x ;\n",
      "\tstore y 1 ;\n",
      "L2:\n",
      "\tjumpF (<= 1 x) L3 ;\n",
      "\tstore y (* y x) ;\n",
      "\tstore x (- x 1) ;\n",
      "\tjump L2 ;\n",
      "L3:\n",
      "\tnoop ;\n",
      "\tprint y ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bytecode = output(instr_tuples)\n",
    "print(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated code is starting to look interesting.  Here is the Cuppa1 source program again,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "get x;\n",
      "y = 1;\n",
      "while (1 <= x)\n",
      "{\n",
      "      y = y * x;\n",
      "      x = x - 1;\n",
      "}\n",
      "put y;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if you can trace through the two programs simultaneously and make sense of the generated Exp1bytecode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiler Correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two ways to execute a Cuppa1 program:\n",
    "\n",
    "1. We can interpret the program directly with the Cuppa1 interpreter from Chapter 5.\n",
    "2. We can first translate the Cuppa1 program into Exp1bytecode and then execute the bytecode in the abstract bytecode machine.\n",
    "\n",
    "Typically we view the interpretation of a programming language as the *reference implementation* for that programming language because interpreters are usually easier to construct. We then say that,\n",
    "\n",
    "> A compiler is *correct* if the translated program, when executed, gives the same results as the interpreted program.\n",
    "\n",
    "Visually we can show this relationship between our Cuppa1 interpreter and our Cuppa1 compiler as in Figure 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figures/chap06/2/figure/Slide1.jpg)\n",
    "<p style=\"text-align: center;\">\n",
    "Fig. 2: A visual representation of the compiler correctness problem.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the idea of compiler correctness is straight forward it is a very challenging problem.  Consider the fact that in order to show that a compiler is correct we will have to show that the relationship shown in Figure 2 holds for *all* Cuppa1 programs.  Now, since most programming languages allow you to write an infinite number of programs the brute force approach to compiler correctness does not work.  For most practical compilers we only use a sampling of all possible programs to show that a compiler is correct.\n",
    "\n",
    "If we were to define the interpreters for both the Cuppa1 language and the Exp1bytecode in terms of mathematical constructs such as first order logic, then it would be possible to prove the correctness of the compiler.  However, the mathematical description of real programming languages such as Java or Python is almost impossible, so therefore we are back to approximating compiler correctness using a *test suite* of source programs.\n",
    "\n",
    "It's an interesting question to see how our Cuppa1 compiler fares in terms of correctness.  In order to take a look at that we define a function `cc` (for Cuppa1 Compiler) that embodies the compiler architecture from above. We will also load the Cuppa1 interpreter and the Exp1bytecode abstract machine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuppa1_lex import lexer\n",
    "from cuppa1_frontend_gram import parser\n",
    "from cuppa1_state import state\n",
    "from cuppa1_cc_codegen import walk as codegen\n",
    "from cuppa1_cc_output import output\n",
    "\n",
    "def cc1(input_stream):\n",
    "    parser.parse(input_stream, lexer=lexer)\n",
    "    instr_tuples = codegen(state.AST)  + [('stop',)]\n",
    "    bytecode = output(instr_tuples)\n",
    "    return bytecode\n",
    "\n",
    "from cuppa1_interp import interp as cuppa1_interp\n",
    "from exp1bytecode_interp import interp as bytecode_interp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test suite is composed of the example programs in the file [`cuppa1_examples.py`](code/cuppa1_examples.py),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuppa1_examples import fact, list, ifex, nested, logical_and, logical_or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin with the `fact` program that will print out the factorial of the number given by the user.  First we will run the interpreter on the program and then we will translate it into Exp1bytecode and execute the bytecode. According to what we said above, in both cases we should see the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value for x? 3\n",
      "> 6\n"
     ]
    }
   ],
   "source": [
    "cuppa1_interp(fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a value for x: 3\n",
      "> 6\n"
     ]
    }
   ],
   "source": [
    "bytecode = cc1(fact)\n",
    "bytecode_interp(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is encouraging, in both cases we got the same result as is required for compiler correctness.  Let's try the program `list`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value for x? 3\n",
      "> 3\n",
      "> 2\n",
      "> 1\n"
     ]
    }
   ],
   "source": [
    "cuppa1_interp(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a value for x: 3\n",
      "> 3\n",
      "> 2\n",
      "> 1\n"
     ]
    }
   ],
   "source": [
    "bytecode = cc1(list)\n",
    "bytecode_interp(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is the `ifex` program,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value for x? 3\n",
      "> 0\n"
     ]
    }
   ],
   "source": [
    "cuppa1_interp(ifex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a value for x: 3\n",
      "> 0\n"
     ]
    }
   ],
   "source": [
    "bytecode = cc1(ifex)\n",
    "bytecode_interp(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `nested` program is next,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2\n"
     ]
    }
   ],
   "source": [
    "cuppa1_interp(nested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2\n"
     ]
    }
   ],
   "source": [
    "bytecode = cc1(nested)\n",
    "bytecode_interp(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we'll test the two programs `logical_and` and `logical_or`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 0\n",
      "> 0\n",
      "> 0\n",
      "> 1\n",
      "> 0\n",
      "> 0\n",
      "> 0\n",
      "> 1\n",
      "> 0\n",
      "> 1\n",
      "> 1\n",
      "> 1\n"
     ]
    }
   ],
   "source": [
    "cuppa1_interp(logical_and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 0\n",
      "> 0\n",
      "> 0\n",
      "> 1\n",
      "> 0\n",
      "> 0\n",
      "> 0\n",
      "> 1\n",
      "> 0\n",
      "> 1\n",
      "> 1\n",
      "> 1\n"
     ]
    }
   ],
   "source": [
    "bytecode = cc1(logical_and)\n",
    "bytecode_interp(bytecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 0\n",
      "> 0\n",
      "> 0\n",
      "> 1\n",
      "> 0\n",
      "> 1\n",
      "> 0\n",
      "> 1\n",
      "> 1\n",
      "> 1\n",
      "> 1\n",
      "> 1\n"
     ]
    }
   ],
   "source": [
    "cuppa1_interp(logical_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 0\n",
      "> 0\n",
      "> 0\n",
      "> 1\n",
      "> 0\n",
      "> 1\n",
      "> 0\n",
      "> 1\n",
      "> 1\n",
      "> 1\n",
      "> 1\n",
      "> 1\n"
     ]
    }
   ],
   "source": [
    "bytecode = cc1(logical_or)\n",
    "bytecode_interp(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our compiler produced correct code for all the programs in our test suite and if you look carefully at the programs you will notice that together they cover all the major features of the Cuppa1 programming language.  That is, our test suite has *good coverage*.  Even though we were not able to test every possible program in the Cuppa1 language the fact that our compiler produced correct results for every program in our test suite increases our confidence that the compiler is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The big difference between interpereters and compilers is that compilers have the ability to think about how to translate a source program into target code in the most effective way.  Usually that means trying to translate the program in such a way that it executes as fast as possible on the target machine.  Interpreters on the other hand are typically machine-agnostic in the sense that they do not try to optimize the program in any way but just execute it as we saw in Chapter 5 when we constructed the Cuppa1 interpreter.  Here we take a look at two optimizations our Cuppa1 compiler performs in order to improve the generated code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Folding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constant folding is an optimization that tries to find arithmetic operations in the source program that can be performed at *compile time* rather than runtime.  Consider the assignment statement,\n",
    "```\n",
    "x = 10 + 5\n",
    "```\n",
    "There is not reason to generate code to perform the addition at runtime since both operands of the addition are constants.  Here the compiler can replace the addition with the constant `15`,\n",
    "```\n",
    "x = 15\n",
    "```\n",
    "without changing the meaning of the program.  Constant folding is considered an optimization because it eliminates the need to perform operations at runtime and therefore improves the runtime performance of the program.  \n",
    "\n",
    "Constant folding by itself is kind of a silly optimization because typically nobody writes code like the assignment above.  However, in conjunction with *constant propagation* and *dead code elimination*, constant folding can become quite powerful and useful.  Constant propogation is a program analysis technique that looks at variables in expressions to see if in fact they act like constants.  In dead code elimination a piece of code is defined as dead if it has no impact on the execution of the program.  Since dead code has no impact on the execution of the code the optimization removes this code to make target programs smaller and more efficient.  Consider the following program,\n",
    "```\n",
    "factor = 2\n",
    "x = factor * 10\n",
    "print x\n",
    "```\n",
    "Constant propagation will realize that the variable `factor` in the assignment expression acts like a constant and will replace the variable with the appropriate constant value,\n",
    "```\n",
    "factor = 2\n",
    "x = 2 * 10\n",
    "print x\n",
    "```\n",
    "Now, our constant folding optimization can compute the value of the expression `2 * 10` and replace the operation with the value `20`. Our program becomes,\n",
    "```\n",
    "factor = 2\n",
    "x = 20\n",
    "print x\n",
    "```\n",
    "Now we can apply constant propagation again to variable `x` in the print statement and we obtain,\n",
    "```\n",
    "factor = 2\n",
    "x = 20\n",
    "print 20\n",
    "```\n",
    "Now, both assignment statements in our program can be considered dead code because they no longer have any kind of impact on our program.  We can eliminate them without changing the behavior of the program!  We obtain,\n",
    "```\n",
    "print 20\n",
    "```\n",
    "We reduced our program to the printing of a constant!  We will look at constant propagation and dead code elimination in Chapter 13.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figures/chap06/3/figure/Slide1.jpg)\n",
    "<p style=\"text-align: center;\">\n",
    "Fig. 3: Constant folding as a tree rewriting process.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, back to the constant folding optimization in our Cuppa1 compiler.  One way to view constant folding is as a AST rewriting process as shown in Figure 3.  Here the AST for the expression `10 + 5` is replaced by an AST node for the constant `15`.  In order to accomplish this we need to walk the AST for a Cuppa1 program and look for patterns that allow us to rewrite the tree.  This is very similar to code generation tree walker where we walked the tree and looked for AST patterns that we could translate into Exp1bytecode.  The big difference being that in the constant folder we will be returning the rewritten tree from the tree walker rather than bytecode as in the code generator.\n",
    "\n",
    "Perhaps the easiest way to explain this is by looking at the code of the [constant folder](code/cuppa1_cc_fold.py).  In particular, the node function for addition,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grammar_stuff import assert_match, dump_AST\n",
    "from cuppa1_cc_fold import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s plus_exp code/cuppa1_cc_fold.py\n",
    "def plus_exp(node):\n",
    "\n",
    "    (OP, c1, c2) = node\n",
    "    assert_match(OP, '+')\n",
    "    \n",
    "    ltree = walk(c1)\n",
    "    rtree = walk(c2)\n",
    "\n",
    "    # if the children are constants -- fold!\n",
    "    if ltree[0] == 'integer' and rtree[0] == 'integer':\n",
    "        return ('integer', ltree[1] + rtree[1])\n",
    "    \n",
    "    else:\n",
    "        return ('+', ltree, rtree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing the node function for addition does is walking the children of an addition AST node.  Remember, in this case this means that walking the tree will rewrite the tree therefore we capture the rewritten child trees and then if the children are constants we fold them by replacing the plus AST node with a constant node.  If it is not possible to fold we take the two new child trees and create a new plus AST and return that.  Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(+ \n",
      "  |(integer 10) \n",
      "  |(integer 1))\n"
     ]
    }
   ],
   "source": [
    "plus_node = ('+', ('integer', 10), ('integer', 1))\n",
    "dump_AST(plus_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('integer', 11)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plus_exp(plus_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the node function for plus expressions folded the addition of the constants 10 and 1 into the constant 11.  If you look at the code for the [constant folder](code/cuppa1_cc_fold.py) you'll see a similar behavior for all the binary arithmetic operations.  It is worthwhile to take a peek at a node function for the binary relational operators to see how they map constants into our truth values of 0 and 1.  Here is the node function for the `==` operation,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s eq_exp code/cuppa1_cc_fold.py\n",
    "def eq_exp(node):\n",
    "\n",
    "    (OP, c1, c2) = node\n",
    "    assert_match(OP, '==')\n",
    "    \n",
    "    ltree = walk(c1)\n",
    "    rtree = walk(c2)\n",
    "\n",
    "    # if the children are constants -- fold!\n",
    "    if ltree[0] == 'integer' and rtree[0] == 'integer':\n",
    "        return ('integer', 1 if ltree[1] == rtree[1] else 0)\n",
    "    \n",
    "    else:\n",
    "        return ('==', ltree, rtree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon folding the node function returns 0 or 1 depending on the result of the Python `==` operation.  This extra step is necessary because the Python `==` operator returns the Python Boolean values of `True` or `False` but in our language these do not exist and therefore need to be mapped into 1 and 0, respectively.  Similar for the `<=` operator.\n",
    "\n",
    "The remaining node functions of the tree walker traverse the AST in search of the patters above.  Notice that all the node functions are very careful to always return trees built from the rewritten child trees.\n",
    "\n",
    "Let's try our walker on our assignment statement example to see if it does what we claim it does,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(assign x \n",
      "  |(+ \n",
      "  |  |(integer 10) \n",
      "  |  |(integer 5)))\n"
     ]
    }
   ],
   "source": [
    "stmt = ('assign', 'x', ('+', ('integer', 10), ('integer', 5)))\n",
    "dump_AST(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuppa1_cc_fold import walk as fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(assign x \n",
      "  |(integer 15))\n"
     ]
    }
   ],
   "source": [
    "new_stmt = fold(stmt)\n",
    "dump_AST(new_stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, we got exactly the result that we expected from the constant folder.  Let's take a look at the next optimization phase for our Cuppa1 compiler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peephole Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you recall the code generator for our Cuppa1 compiler translates Cuppa1 AST patterns into Exp1bytecode patterns and simply composes the generated bytecode patterns into a list of instructions.  That can lead to very silly looking code.  Consider the `fact` program from our Cuppa1 example programs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuppa1_examples import fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "get x;\n",
      "y = 1;\n",
      "while (1 <= x)\n",
      "{\n",
      "      y = y * x;\n",
      "      x = x - 1;\n",
      "}\n",
      "put y;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the compiler function we developed above to this program gives us,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytecode = cc1(fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tinput x ;\n",
      "\tstore y 1 ;\n",
      "L13:\n",
      "\tjumpF (<= 1 x) L14 ;\n",
      "\tstore y (* y x) ;\n",
      "\tstore x (- x 1) ;\n",
      "\tjump L13 ;\n",
      "L14:\n",
      "\tnoop ;\n",
      "\tprint y ;\n",
      "\tstop ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the two lines of code following the second label definition.  Because we are just composing target patterns we wind up with a strange and useless `noop` instruction right at the label definition.  We would like our compiler to output code that looks like this,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bytecode = \\\n",
    "'''\n",
    "    input x ;\n",
    "    store y 1 ;\n",
    "L13:\n",
    "    jumpF (<= 1 x) L14 ;\n",
    "    store y (* y x) ;\n",
    "    store x (- x 1) ;\n",
    "    jump L13 ;\n",
    "L14:\n",
    "    print y ;\n",
    "    stop ;\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The situation gets even worse when we start nesting structured programming constructs.  Here is a silly program that only considers even numbers that have a value of less or equal to 10,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_even = \\\n",
    "'''\n",
    "get x\n",
    "r = x - 2*(x/2)\n",
    "if (not r)\n",
    "  if (x <= 10)\n",
    "    put x\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value for x? 3\n"
     ]
    }
   ],
   "source": [
    "cuppa1_interp(print_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytecode = cc1(print_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tinput x ;\n",
      "\tstore r (- x (* 2 (/ x 2))) ;\n",
      "\tjumpF !r L15 ;\n",
      "\tjumpF (<= x 10) L16 ;\n",
      "\tprint x ;\n",
      "L16:\n",
      "\tnoop ;\n",
      "L15:\n",
      "\tnoop ;\n",
      "\tstop ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the generated code has a cascade of `noop` instructions that serve as placeholders for various label definitions.  What we would like to see as generated code from our compiler in this instance is,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bytecode = \\\n",
    "'''\n",
    "input x ;\n",
    "    store r (- x (* 2 (/ x 2))) ;\n",
    "    jumpF !r L15 ;\n",
    "    jumpF (<= x 10) L15 ;\n",
    "    print x ;\n",
    "L15:\n",
    "    stop ;\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code changes we performed in these examples can be accomplished by applying rewrite rules to the generated code.  For example, in the first instance where we had a label definition on a `noop` instruction followed by other unlabeled instructions we can just delete the `noop` instruction.  This gives rise to the following rewrite rule:\n",
    "```\n",
    "L:\n",
    "    noop\n",
    "    <other instruction>\n",
    "\n",
    "=>\n",
    "\n",
    "L:\n",
    "    <other instruction>\n",
    "```\n",
    "In the second example we had a cascade of label definitions and `noop` instructions.  The last `noop` in cascade will be taken care of by our previous pattern if there are instructions following that `noop`.  However, in order to get rid of that first `noop` we need a new rewrite rule,\n",
    "```\n",
    "L1:\n",
    "    noop\n",
    "L2:\n",
    "    <other instruction>\n",
    "=>\n",
    "\n",
    "L2:  -- with L1 backpatched to L2\n",
    "    <other instruction>\n",
    "```\n",
    "The pattern refers to *backpatching* which means that all references to the label defintion `L1` are rewritten as references to label definition `L2`.  That is exactly what happens in the examples above.  A label references to `L15` are rewritten as label references to `L16` and the label definition of `L15` is deleted from the code together with its `noop` instruction.  Now it might dawn you on why our codegenerator generates code as a list of instructions because a list of instructions is easy to rewrite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Design of a Peephole Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to think of a peephole optimizer is as a window (the peephole) which we slide across the generated instructions repeatedly and apply rewrite rules like the ones we developed above to the code within the window.  The peephole optimizer terminates once no longer any code is being rewritten. Figure 4 shows the basic architecture of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](figures/chap06/4/figure/Slide1.jpg)\n",
    "<p style=\"text-align: center;\">\n",
    "Fig. 4: The design of a peephole optimizer.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The repeated nature of the process is necessary because applying one rewrite rule to the instruction list can expose opportunities to apply other rewrite rules.  So we need to keep sliding the window accross the instructions until no further rewrites are possible.\n",
    "\n",
    "Peephole optimizers are conceptually very simple but very effective in improving the quality of the generated code.  Our peephole optimizer is part of the Cuppa1 compiler [output phase](code/cuppa1_cc_output.py) we discussed earlier where the list of generated instruction tuples is converted to actual Exp1bytecode instructions.  The optimizer consists of a loop that moves the peephole across the instruction tuple list and tries to apply three rewrite rules in order to improve the code,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s peephole_opt code/cuppa1_cc_output.py\n",
    "def peephole_opt(instr_stream):\n",
    "\n",
    "    ix = 0\n",
    "    change = False\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        # uncomment the following to see the pattern matcher in action\n",
    "        #if pattern_fits(3, ix, instr_stream):\n",
    "        #    print(\"at ix={}\".format(ix))\n",
    "        #    print(instr_stream[ix])\n",
    "        #    print(instr_stream[ix+1])\n",
    "        #    print(instr_stream[ix+2])\n",
    "\n",
    "        curr_instr = instr_stream[ix]\n",
    "\n",
    "        ### compute some useful predicates on the current instruction\n",
    "        is_first_instr = ix == 0\n",
    "        is_last_instr = ix+1 == len(instr_stream)\n",
    "        has_label = True if not is_first_instr and label_def(instr_stream[ix-1]) else False\n",
    "\n",
    "        ### our peephole rewrite rules\n",
    "        \n",
    "        # rewrite rule:\n",
    "        # *L:\n",
    "        #      noop\n",
    "        #      <some other instr>\n",
    "        # =>\n",
    "        # *L:\n",
    "        #      <some other instr>\n",
    "        if pattern_fits(3, ix, instr_stream) and \\\n",
    "           label_def(curr_instr) and \\\n",
    "           relative_instr(1, ix, instr_stream)[0] == 'noop' and \\\n",
    "           not label_def(relative_instr(2, ix, instr_stream)):\n",
    "             # delete noop\n",
    "             instr_stream.pop(ix+1)\n",
    "             change = True\n",
    "             # uncomment the following to see the pattern matcher in action\n",
    "             #print(\"fire rule 1\")\n",
    "\n",
    "        # rewrite rule:\n",
    "        # * noop\n",
    "        # =>\n",
    "        # * <whatever followed the noop>\n",
    "        elif pattern_fits(1, ix, instr_stream) and \\\n",
    "             curr_instr[0] == 'noop' and \\\n",
    "             not has_label:\n",
    "            instr_stream.pop(ix)\n",
    "            change = True\n",
    "             # uncomment the following to see the pattern matcher in action\n",
    "             #print(\"fire rule 2\")\n",
    "            \n",
    "        # rewrite rule:\n",
    "        # *L1:\n",
    "        #    noop\n",
    "        #  L2:\n",
    "        # =>\n",
    "        # *L2:  -- with L1 backpatched to L2 in instr_stream\n",
    "        elif pattern_fits(3, ix, instr_stream) and \\\n",
    "             label_def(curr_instr) and \\\n",
    "             relative_instr(1, ix, instr_stream)[0] == 'noop' and \\\n",
    "             label_def(relative_instr(2, ix, instr_stream)):\n",
    "            label1 = get_label_from_def(curr_instr)\n",
    "            label2 = get_label_from_def(relative_instr(2, ix, instr_stream))\n",
    "            backpatch_label(label1, label2, instr_stream)\n",
    "            instr_stream.pop(ix)\n",
    "            instr_stream.pop(ix)\n",
    "            change = True\n",
    "            # uncomment the following to see the pattern matcher in action\n",
    "            #print(\"fire rule 3\")\n",
    "\n",
    "        ###  advance ix\n",
    "        if is_last_instr and not change:\n",
    "            break\n",
    "\n",
    "        elif is_last_instr:\n",
    "            ix = 0\n",
    "            change = False\n",
    "\n",
    "        else:\n",
    "            ix += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of the three rewrite rules in the peephole optimizer are the rules we discussed earlier where we delete unnecessary `noop` instructions and superfluous label definitions taking care of backpatching the label names properly.  The third rewrite rule is a rule that removes standalone `noop` instructions.  Notice that all the rewrite rules follow the same schema.  Consider the first rule,\n",
    "```Python\n",
    "# rewrite rule:\n",
    "# *L:\n",
    "#      noop\n",
    "#      <some other instr>\n",
    "# =>\n",
    "# *L:\n",
    "#      <some other instr>\n",
    "if pattern_fits(3, ix, instr_stream) and \\\n",
    "   label_def(curr_instr) and \\\n",
    "   relative_instr(1, ix, instr_stream)[0] == 'noop' and \\\n",
    "   not label_def(relative_instr(2, ix, instr_stream)):\n",
    "     # delete noop\n",
    "     instr_stream.pop(ix+1)\n",
    "     change = True\n",
    "```\n",
    "We first make sure that the current window is in a position where it encompasses at least three instructions.\n",
    "The next thing is to look at the first three instruction in the current window to see if they fit the left side of our rewrite rule.  In our case that means the first instruction needs to be a label definition, the second instruction a `noop` instruction, the third instruction is not allowed to be a label definition.  Here the function `relative_instr` returns the instruction tuple relative to the beginning of the peephole.  If all the conditions of the left side of the rewrite rule hold then we are allowed to delete the `noop` instruction, that is, execute the right side of the rewrite rule.  We also need to record that we did change the code.\n",
    "\n",
    "Just in case you were wondering, the asterisks in the comments of the rewrite rules indicate the beginning of the peephole.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our peephole optimizer to see if it performs as intended. We start with the factorial program from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuppa1_cc_output import peephole_opt, output\n",
    "from cuppa1_frontend_gram import parser\n",
    "from cuppa1_cc_codegen import walk as codegen\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "get x;\n",
      "y = 1;\n",
      "while (1 <= x)\n",
      "{\n",
      "      y = y * x;\n",
      "      x = x - 1;\n",
      "}\n",
      "put y;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytecode = cc1(fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tinput x ;\n",
      "\tstore y 1 ;\n",
      "L17:\n",
      "\tjumpF (<= 1 x) L18 ;\n",
      "\tstore y (* y x) ;\n",
      "\tstore x (- x 1) ;\n",
      "\tjump L17 ;\n",
      "L18:\n",
      "\tnoop ;\n",
      "\tprint y ;\n",
      "\tstop ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now let's try optimizing this code,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('input', 'x'),\n",
      " ('store', 'y', '1'),\n",
      " ('L19:',),\n",
      " ('jumpF', '(<= 1 x)', 'L20'),\n",
      " ('store', 'y', '(* y x)'),\n",
      " ('store', 'x', '(- x 1)'),\n",
      " ('jump', 'L19'),\n",
      " ('L20:',),\n",
      " ('noop',),\n",
      " ('print', 'y'),\n",
      " ('stop',)]\n"
     ]
    }
   ],
   "source": [
    "parser.parse(fact, lexer=lexer)\n",
    "instr_tuples = codegen(state.AST)  + [('stop',)]\n",
    "pprint(instr_tuples, width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('input', 'x'),\n",
      " ('store', 'y', '1'),\n",
      " ('L19:',),\n",
      " ('jumpF', '(<= 1 x)', 'L20'),\n",
      " ('store', 'y', '(* y x)'),\n",
      " ('store', 'x', '(- x 1)'),\n",
      " ('jump', 'L19'),\n",
      " ('L20:',),\n",
      " ('print', 'y'),\n",
      " ('stop',)]\n"
     ]
    }
   ],
   "source": [
    "peephole_opt(instr_tuples)\n",
    "pprint(instr_tuples, width=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in a more readable format,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tinput x ;\n",
      "\tstore y 1 ;\n",
      "L19:\n",
      "\tjumpF (<= 1 x) L20 ;\n",
      "\tstore y (* y x) ;\n",
      "\tstore x (- x 1) ;\n",
      "\tjump L19 ;\n",
      "L20:\n",
      "\tprint y ;\n",
      "\tstop ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output(instr_tuples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The peephole optimizer deleted the `noop` instruction!  Let's try the second example with the nested if statements,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "get x\n",
      "r = x - 2*(x/2)\n",
      "if (not r)\n",
      "  if (x <= 10)\n",
      "    put x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(print_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('input', 'x'),\n",
      " ('store', 'r', '(- x (* 2 (/ x 2)))'),\n",
      " ('jumpF', '!r', 'L21'),\n",
      " ('jumpF', '(<= x 10)', 'L22'),\n",
      " ('print', 'x'),\n",
      " ('L22:',),\n",
      " ('noop',),\n",
      " ('L21:',),\n",
      " ('noop',),\n",
      " ('stop',)]\n"
     ]
    }
   ],
   "source": [
    "parser.parse(print_even, lexer=lexer)\n",
    "instr_tuples = codegen(state.AST)  + [('stop',)]\n",
    "pprint(instr_tuples, width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tinput x ;\n",
      "\tstore r (- x (* 2 (/ x 2))) ;\n",
      "\tjumpF !r L21 ;\n",
      "\tjumpF (<= x 10) L22 ;\n",
      "\tprint x ;\n",
      "L22:\n",
      "\tnoop ;\n",
      "L21:\n",
      "\tnoop ;\n",
      "\tstop ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output(instr_tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('input', 'x'),\n",
      " ('store', 'r', '(- x (* 2 (/ x 2)))'),\n",
      " ('jumpF', '!r', 'L21'),\n",
      " ('jumpF', '(<= x 10)', 'L21'),\n",
      " ('print', 'x'),\n",
      " ('L21:',),\n",
      " ('stop',)]\n"
     ]
    }
   ],
   "source": [
    "peephole_opt(instr_tuples)\n",
    "pprint(instr_tuples, width=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tinput x ;\n",
      "\tstore r (- x (* 2 (/ x 2))) ;\n",
      "\tjumpF !r L21 ;\n",
      "\tjumpF (<= x 10) L21 ;\n",
      "\tprint x ;\n",
      "L21:\n",
      "\tstop ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output(instr_tuples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is where our peephole optimizer really shines: it deleted one label definition and two unnecessary `noop` instructions making the code much more readable and more efficient.  Notice the backpatched label reference in the second `jumpF` instruction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cc1` function we wrote above that runs the frontend, the code generator, and the output formatter gets us almost there.  All we have to do is incorporate our two optimization phases.  Here we define the function `cc` that takes an input stream and a optimization flag as arguments, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "# %load code/cuppa1_cc.py\n",
    "#!/usr/bin/env python\n",
    "# Cuppa1 compiler\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from cuppa1_lex import lexer\n",
    "from cuppa1_frontend_gram import parser\n",
    "from cuppa1_state import state\n",
    "from cuppa1_cc_codegen import walk as codegen\n",
    "from cuppa1_cc_fold import walk as fold\n",
    "from cuppa1_cc_output import output\n",
    "from cuppa1_cc_output import peephole_opt\n",
    "\n",
    "def cc(input_stream, opt = False):\n",
    "\n",
    "    # initialize the state object\n",
    "    state.initialize()\n",
    "\n",
    "    # build the AST\n",
    "    parser.parse(input_stream, lexer=lexer)\n",
    "\n",
    "    # run the constant fold optimizer\n",
    "    if opt:\n",
    "        state.AST = fold(state.AST)\n",
    "\n",
    "    # generate the list of instruction tuples\n",
    "    instr_stream = codegen(state.AST) + [('stop',)]\n",
    "\n",
    "    # run the peephole optimizer\n",
    "    if opt:\n",
    "        peephole_opt(instr_stream)\n",
    "\n",
    "    # output the instruction stream\n",
    "    bytecode = output(instr_stream)\n",
    "\n",
    "    return bytecode\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # parse command line args\n",
    "    aparser = ArgumentParser()\n",
    "    aparser.add_argument('-O', action='store_true', help='optimization flag')\n",
    "    aparser.add_argument('input', metavar='input_file', help='cuppa1 input file')\n",
    "    aparser.add_argument('-o', metavar='output_file', help='exp1bytecode output file')\n",
    "    \n",
    "    args = vars(aparser.parse_args())\n",
    "    \n",
    "    f = open(args['input'], 'r')\n",
    "    input_stream = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    # run the compiler\n",
    "    bytecode = cc(input_stream=input_stream, opt=args['O'])\n",
    "\n",
    "    if not args['o']:\n",
    "        print(bytecode)\n",
    "\n",
    "    else:\n",
    "        f = open(args['o'], 'w')\n",
    "        f.write(bytecode)\n",
    "        f.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as the function `cc1` above our `cc` function runs the Cuppa1 frontend, the code generator, and the output formatter.  However, the big difference is that it also runs the constant folding optimization on the AST generated by the frontend if optimizations are turned on.  It also runs the peephole optimizer on the generated list of instruction tuples if enabled.  \n",
    "\n",
    "Just as our interpreters in the previous chapters we want to be able to run our compiler directly from the commandline.  The code that accomplishes that is in the if statement at the bottom of the file.  The compiler will accept an input file and the user is able to set two flags.  One flag is the optimization flag (`-O`) and the other flag is the output flag (`-o output_file`) allowing the user to store the bytecode in a file rather than having it printed to the terminal.\n",
    "\n",
    "Let's test our new compiler function on the programs we used for testing above,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuppa1_cc import cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tinput x ;\n",
      "\tstore y 1 ;\n",
      "L23:\n",
      "\tjumpF (<= 1 x) L24 ;\n",
      "\tstore y (* y x) ;\n",
      "\tstore x (- x 1) ;\n",
      "\tjump L23 ;\n",
      "L24:\n",
      "\tprint y ;\n",
      "\tstop ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bytecode = cc(fact, opt=True)\n",
    "print(bytecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tinput x ;\n",
      "\tstore r (- x (* 2 (/ x 2))) ;\n",
      "\tjumpF !r L25 ;\n",
      "\tjumpF (<= x 10) L25 ;\n",
      "\tprint x ;\n",
      "L25:\n",
      "\tstop ;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bytecode = cc(print_even, opt=True)\n",
    "print(bytecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started our discussion of compilers by looking at a basic compiler that translates Cuppa1 programs into Exp1bytecode.  This raised the question of compiler correctness.  Here we looked at compiler correctness in context of our Cuppa1 interpreter from Chapter 5: A compiler is correct if when a translated program is executed it gives the same results as the interpreted source program. We finished the chapter by discussing our constant folding and peephole optimizations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any book on compiler construction, i.e. (Watson, 2017), will discuss the above material.  A book that discusses both interpreters and compilers is (Mak, 2011).  A really nice book on programming language implementation is Randy Kaplan's \"Constructing language processors for little languages.\", (Kaplan, 1994). Even though the paper is fairly old it is still highly relevant. \"Little languages\" are domain specific languages that developed for one particular tasks such as HTML markup for example.  Probably one of the original papers that discusses little languages is (Bentley, 1986).  A completely different approach to compiler construction using Python compared to our approach is given in (Aycock, 1998).  A complete compiler implementation for a small C-like language is discussed in (Benders *et al.*, 2003).  Another classic book on compiler construction is (Holub, 1990).\n",
    "\n",
    "\n",
    "Watson, D. (2017). [*A Practical Approach to Compiler Construction*](https://link.springer.com/book/10.1007/978-3-319-52789-5). Undergraduate Topics in Computer Science, Springer.\n",
    "\n",
    "Mak, R. (2011). [*Writing compilers and interpreters: a software engineering approach*](http://www.wiley.com/WileyCDA/WileyTitle/productCd-1118079736.html). John Wiley & Sons.\n",
    "\n",
    "Kaplan, R. M. (1994). *Constructing language processors for little languages*. John Wiley & Sons, Inc.\n",
    "\n",
    "Bentley, J. (1986). [*Programming pearls: little languages*](http://dl.acm.org/citation.cfm?id=315691). Communications of the ACM, 29(8), 711-721.\n",
    "\n",
    "Aycock, J. (1998, November). [*Compiling little languages in Python*](http://legacy.python.org/workshops/1998-11/proceedings/papers/aycock-little/aycock-little.html). In Proceedings of the 7th International Python Conference (pp. 69-77).\n",
    "\n",
    "Benders, F. J. F., Haaring, J. W., Janssen, T. H., Meffert, D., & van Oostenrijk, A. C. (2003). [*Compiler Construction A Practical Approach*](http://www.independent-software.com/share/CompilerConstruction.pdf).\n",
    "\n",
    "Holub, A. I. (1990). [*Compiler design in C*](http://holub.com/compiler/). Prentice Hall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a compiler of Cuppa2 programs into your favorite programming language.\n",
    "\n",
    "1. Write a compiler of Cuppa2 programs into Java virtual machine code.\n",
    "\n",
    "1. Write a compiler of Cuppa2 programs into Intel assembly code.\n",
    "\n",
    "1. Given the [lexer](code/ubasic_lex.py) and the [parser specification](code/ubasic_gram.py) for uBasic (micro-Basic) in the [code](code) folder develop a compiler that translates this language into your favorite programming language.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
